{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads the data from trajectory_analysis_script.py for whichever data set is needed. The point is to look at the density of the tracks/localizations per area of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/qlzp5l894v16vmr8m_81x5x80000gn/T/ipykernel_58546/1068179213.py:30: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "from src.databases.trajectory_analysis_script import *\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.colors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from scipy.stats import gaussian_kde\n",
    "import os\n",
    "import numpy as np\n",
    "from src.helpers.plotting_functions import *\n",
    "from src.helpers.import_functions import *\n",
    "from src.helpers.Analysis_functions import *\n",
    "from src.helpers.diff_mw import *\n",
    "import mpl_toolkits.mplot3d.art3d as art3d\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import matplotlib as mpl\n",
    "from src.helpers.scalebars import *\n",
    "from src.helpers.Convert_csv_mat import *\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from scipy import stats  \n",
    "import csv  \n",
    "from sklearn.cluster import OPTICS\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')  \n",
    "from sklearn.cluster import DBSCAN\n",
    "from cgitb import small\n",
    "import src.helpers.smallestenclosingcircle as smallestenclosingcircle\n",
    "import math\n",
    "import src.helpers.guassian_fit as gaussian_fit\n",
    "import src.helpers.fbm_utility as fbm_utility\n",
    "import src.helpers.simulate_foci as simulate_foci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals = {\"olympus_pixel_size\":130,\"confocal_pixel_size\":79}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find files\n",
    "def find_files(path, extension, keyword = None):\n",
    "    '''\n",
    "    Docstring for find_files\n",
    "    Finds files in a directory with a specific extension and keyword in the name\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        path to the directory where the files are located\n",
    "    extension : str\n",
    "        extension of the files to be found\n",
    "    keyword : str    \n",
    "        keyword to be searched in the file name\n",
    "    Returns:\n",
    "    --------\n",
    "    files : list\n",
    "        list of files that match the criteria\n",
    "    '''\n",
    "    #find all images in the directory using import functions\n",
    "    files = import_functions.find_image(path=path,ends_with=extension,full_path=True)\n",
    "    #sort the files to get only ones conatining the word \"RFP\" for the flourescent protein\n",
    "    files = import_functions.name_sorter(strings=files,keyword=keyword)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run detection on a set of files \n",
    "def utility_batch_blob_detection(files,detection_args,fitting_args,focal_plane=None,project=False):\n",
    "    '''\n",
    "    Docstring for utility_batch_blob_detection\n",
    "    Runs blob detection on a set of files and returns the blobs in a list\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    files : list\n",
    "        list of files to be analyzed\n",
    "    detection_args : dict\n",
    "        dictionary of arguments for the blob detection\n",
    "    fitting_args : dict \n",
    "        dictionary of arguments for the blob fitting\n",
    "    focal_plane : int\n",
    "        focal plane to be analyzed in each image (default is None if there is only one plane)\n",
    "    project : bool\n",
    "        whether or not to project the image using max (default is False), focal_plane must be None if project is True\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    blobs : list\n",
    "        list of blobs detected in each image aggregated in a list\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    This doesn't care if the detection is verbose, the list may be a list of lists or a list of dictionaries, see blob_detection.detection for more details\n",
    "    '''\n",
    "    blobs=[]\n",
    "    for i in files:\n",
    "        if project:\n",
    "            img = np.max(io.imread(i),axis=0)\n",
    "        else:\n",
    "            img = io.imread(i)[focal_plane]\n",
    "        blob_detector = blob_detection(path=img,**detection_args)\n",
    "        blob_detector._update_fitting_parameters(kwargs=fitting_args)\n",
    "        #detect blobs\n",
    "        c = blob_detector.detection(type=\"bp\")\n",
    "        #if c's shape's first element is 0, then there are no blobs detected and we don't want to add it to the list\n",
    "        if blob_detector.verbose:\n",
    "            if c[\"Fitted\"].shape[0] != 0:\n",
    "                blobs.append(c[\"Fitted\"])\n",
    "        else:\n",
    "            if c.shape[0] != 0:\n",
    "                blobs.append(c)\n",
    "            \n",
    "    return blobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the blob detection on hupA images and generic RpoC images from the confocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of paths of hupa images\n",
    "hupa_dir_list = [\"/Volumes/WEBERLAB/HupA_confocal/191113_TC_WLBS81(HupA)/t120/\",\n",
    "                \"/Volumes/WEBERLAB/HupA_confocal/191205_TC_WLBS81(HupA)/t120\",\n",
    "                \"/Volumes/WEBERLAB/HupA_confocal/191223_TC_WLBS81(HupA)/t120\",\n",
    "                \"/Volumes/WEBERLAB/HupA_confocal/191230_TC_WLBS81(HupA)/t120\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory of AML's rpoc images\n",
    "aml_rpoc_dir = \"/Volumes/WEBERLAB/HupA_confocal/thirty-seven/120\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using find_files, find hupa files\n",
    "#using all the hupa directories find all the files with the keyword \"RFP\"\n",
    "files_hupa = []\n",
    "for i in hupa_dir_list:\n",
    "    files_hupa+=find_files(path=i,extension=\"*.tif\",keyword=\"RFP\")\n",
    "#using find_files, find rpoc files\n",
    "files_rpoc = find_files(path=\"/Volumes/WEBERLAB/HupA_confocal/191205_TC_WLBS100(rpoC)/t120\",extension=\"*.tif\",keyword=\"RFP\")\n",
    "#find aml rpoc files\n",
    "files_aml_rpoc = find_files(path=aml_rpoc_dir,extension=\"*.tif\",keyword=\"RFP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the parameters for blob detection\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":7e-2,\n",
    "                \"min_sigma\":1./np.sqrt(2),\n",
    "                \"max_sigma\":20./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":True}\n",
    "fitting_args = {\"mask_size\":4,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":None,\n",
    "                \"residual_func\":residuals_gaus2d,\n",
    "                \"sigma_range\":0.5,\n",
    "                \"centeroid_range\":0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run utility_batch_blob_detection on the hupa files\n",
    "blobs_hupa = utility_batch_blob_detection(files_hupa,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)\n",
    "#run utility_batch_blob_detection on the rpoc files\n",
    "blobs_rpoc = utility_batch_blob_detection(files_rpoc,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)\n",
    "#run utility_batch_blob_detection on the aml rpoc files\n",
    "blobs_aml_rpoc = utility_batch_blob_detection(files_aml_rpoc,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo the detection on the AML rpoC images with detection args with threshold changed \n",
    "detection_args_AML = detection_args.copy()\n",
    "detection_args_AML[\"threshold\"] = 1e-1\n",
    "detection_args_AML[\"overlap\"] = 0\n",
    "#run utility_batch_blob_detection on the aml rpoc files\n",
    "blobs_aml_rpoc = utility_batch_blob_detection(files_aml_rpoc,detection_args=detection_args_AML,fitting_args=fitting_args,focal_plane=3,project=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_blob_sizes(blobs,verbose=False):\n",
    "    '''Return a flattened list of blob sizes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    blobs : list\n",
    "        list of blobs detected in each image aggregated in a list\n",
    "    verbose : bool\n",
    "        True whether the blobs are Fitted and have sigma_x, and sigma_y. Or Flase if isotropic gaussian is used/Scale space (default is False)\n",
    "    '''\n",
    "    if verbose:\n",
    "        return [np.concatenate([i[:,2] for i in blobs]).ravel(),np.concatenate([i[:,3] for i in blobs]).ravel()]\n",
    "    else:\n",
    "        return np.concatenate([i[:,2] for i in blobs]).ravel()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sizes of the blobs if verbose is True, if false do not run this cell\n",
    "sizes_hupa = get_blob_sizes(blobs_hupa,verbose=True)\n",
    "sizes_rpoc = get_blob_sizes(blobs_rpoc,verbose=True)\n",
    "sizes_aml_rpoc = get_blob_sizes(blobs_aml_rpoc,verbose=True)\n",
    "\n",
    "#for each, find the ratio of the x and y sigma\n",
    "ratio_hupa = sizes_hupa[0]/sizes_hupa[1]\n",
    "ratio_rpoc = sizes_rpoc[0]/sizes_rpoc[1]\n",
    "ratio_aml_rpoc = sizes_aml_rpoc[0]/sizes_aml_rpoc[1]\n",
    "\n",
    "#plot the ratio of the x and y sigma as a histogram with the bins=20\n",
    "#Make sure the weights are normalized\n",
    "\n",
    "#make a figure with two subplots\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "#redo the first plot on the first axis\n",
    "ax[0].hist(ratio_hupa,bins=20,weights=np.ones_like(ratio_hupa)/len(ratio_hupa),label=\"HupA\",alpha=0.2)\n",
    "ax[0].hist(ratio_rpoc,bins=20,weights=np.ones_like(ratio_rpoc)/len(ratio_rpoc),label=\"rpoC\",alpha=0.2)\n",
    "ax[0].hist(ratio_aml_rpoc,bins=20,weights=np.ones_like(ratio_aml_rpoc)/len(ratio_aml_rpoc),label=\"AML rpoC\",alpha=0.2)\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(r\"$\\frac{\\sigma_x}{\\sigma_y}$\",fontsize=20)\n",
    "ax[0].set_ylabel(\"Probability\")\n",
    "ax[0].set_title(\"Ratio of x and y sigma for HupA and rpoC blobs\")\n",
    "#redo the second plot on the second axis\n",
    "#find the mean of each x,y pair\n",
    "#make sure to divide by sqrt(2) because of the blob_detection output scales the sigma by sqrt(2)\n",
    "\n",
    "mean_hupa = np.mean(sizes_hupa,axis=0)/np.sqrt(2)\n",
    "mean_rpoc = np.mean(sizes_rpoc,axis=0)/np.sqrt(2)\n",
    "mean_aml_rpoc = np.mean(sizes_aml_rpoc,axis=0)/np.sqrt(2)\n",
    "\n",
    "#plot the mean of the x and y sigma vs the ratios calculated above, make sure to multiply the mean by the confocal pixel size to get the correct units in nm\n",
    "ax[1].scatter(mean_hupa*globals[\"confocal_pixel_size\"],ratio_hupa,label=\"HupA\")\n",
    "ax[1].scatter(mean_rpoc*globals[\"confocal_pixel_size\"],ratio_rpoc,label=\"rpoC\")\n",
    "ax[1].scatter(mean_aml_rpoc*globals[\"confocal_pixel_size\"],ratio_aml_rpoc,label=\"AML rpoC\")\n",
    "ax[1].legend()\n",
    "#write the the sigma as greek letters and make the font size of the labels bigger\n",
    "\n",
    "ax[1].set_ylabel(r\"$\\frac{\\sigma_x}{\\sigma_y}$\",fontsize=20)\n",
    "ax[1].set_xlabel(r\"$\\frac{\\sigma_x + \\sigma_y}{2}$ nm\",fontsize=20)\n",
    "ax[1].set_title(\"Mean of x and y sigma vs \\n Ratio of x and y sigma for HupA and rpoC blobs\")\n",
    "#make the plot look nice\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#find the absolute differences in the x and y sigmas for each blob\n",
    "diff_hupa = np.abs(sizes_hupa[0]-sizes_hupa[1])/np.sqrt(2)\n",
    "diff_rpoc = np.abs(sizes_rpoc[0]-sizes_rpoc[1])/np.sqrt(2)\n",
    "diff_aml_rpoc = np.abs(sizes_aml_rpoc[0]-sizes_aml_rpoc[1])/np.sqrt(2)\n",
    "\n",
    "#plot this as a scatter plot vs the mean of the x and y sigmas\n",
    "#make a figure with one subplot\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "#plot the scatter plot\n",
    "ax.scatter(mean_hupa*globals[\"confocal_pixel_size\"],diff_hupa*globals[\"confocal_pixel_size\"],label=\"HupA\")\n",
    "ax.scatter(mean_rpoc*globals[\"confocal_pixel_size\"],diff_rpoc*globals[\"confocal_pixel_size\"],label=\"rpoC\")\n",
    "ax.scatter(mean_aml_rpoc*globals[\"confocal_pixel_size\"],diff_aml_rpoc*globals[\"confocal_pixel_size\"],label=\"AML rpoC\")\n",
    "ax.legend()\n",
    "#write the the sigma as greek letters and make the font size of the labels bigger\n",
    "#the y label is the absolute difference of the x and y sigma\n",
    "ax.set_ylabel(r\"$\\left|\\sigma_x - \\sigma_y\\right|$ nm\",fontsize=20)\n",
    "ax.set_xlabel(r\"$\\frac{\\sigma_x + \\sigma_y}{2}$ nm\",fontsize=20)\n",
    "ax.set_title(\"Mean of x and y sigma vs \\n Absolute difference of x and y sigma for HupA and rpoC blobs\")\n",
    "#make the plot look nice\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the detection parameter verbose to False to see the progress of the blob detection\n",
    "detection_args[\"verbose\"] = False\n",
    "\n",
    "#run utility_batch_blob_detection on the hupa files\n",
    "blobs_hupa = utility_batch_blob_detection(files_hupa,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)\n",
    "#run utility_batch_blob_detection on the rpoc files\n",
    "blobs_rpoc = utility_batch_blob_detection(files_rpoc,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)\n",
    "#run utility_batch_blob_detection on the aml rpoc files\n",
    "blobs_aml_rpoc = utility_batch_blob_detection(files_aml_rpoc,detection_args=detection_args,fitting_args=fitting_args,focal_plane=3,project=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot the two sizes on the same histogram plot with a legend and alpha transparency of 0.2, this does not work if verbose is True, do not run this cell if verbose is True\n",
    "sizes_hupa = get_blob_sizes(blobs_hupa,verbose=False)\n",
    "sizes_rpoc = get_blob_sizes(blobs_rpoc,verbose=False)\n",
    "sizes_aml_rpoc = get_blob_sizes(blobs_aml_rpoc,verbose=False)\n",
    "\n",
    "#make a figure with one subplot\n",
    "plt.clf()\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "#plot the histograms with the weights normaized to 1\n",
    "ax.hist(sizes_hupa*globals[\"confocal_pixel_size\"],bins=10,weights=np.ones_like(sizes_hupa)/len(sizes_hupa),label=\"HupA\",alpha=0.2)\n",
    "ax.hist(sizes_rpoc*globals[\"confocal_pixel_size\"],bins=10,weights=np.ones_like(sizes_rpoc)/len(sizes_rpoc),label=\"rpoC\",alpha=0.2)\n",
    "ax.hist(sizes_aml_rpoc*globals[\"confocal_pixel_size\"],bins=10,weights=np.ones_like(sizes_aml_rpoc)/len(sizes_aml_rpoc),label=\"AML rpoC\",alpha=0.2)\n",
    "\n",
    "#set the x and y labels\n",
    "ax.set_xlabel(\"Size of blob (nm)\")\n",
    "ax.set_ylabel(\"Probaility\")\n",
    "#add a title\n",
    "ax.set_title(\"Size of HupA and rpoC Blobs from Confocal Images\")\n",
    "#add an annotation for the mean and standard deviation for each distribution \n",
    "ax.annotate(\"HupA: $\\mu$ = {:.2f} nm, $\\sigma$ = {:.2f} nm\".format(np.mean(sizes_hupa*globals[\"confocal_pixel_size\"]),np.std(sizes_hupa*globals[\"confocal_pixel_size\"])),xy=(0.05,0.9),xycoords=\"axes fraction\")\n",
    "ax.annotate(\"rpoC: $\\mu$ = {:.2f} nm, $\\sigma$ = {:.2f} nm\".format(np.mean(sizes_rpoc*globals[\"confocal_pixel_size\"]),np.std(sizes_rpoc*globals[\"confocal_pixel_size\"])),xy=(0.05,0.85),xycoords=\"axes fraction\")\n",
    "ax.annotate(\"AML's rpoC: $\\mu$ = {:.2f} nm, $\\sigma$ = {:.2f} nm\".format(np.mean(sizes_aml_rpoc*globals[\"confocal_pixel_size\"]),np.std(sizes_aml_rpoc*globals[\"confocal_pixel_size\"])),xy=(0.05,0.75),xycoords=\"axes fraction\")\n",
    "#annotate the result of a ks test both the p value and the statistic\n",
    "ax.annotate(\"K-S Test: p_val = {:.2e}, D = {:.2f}\".format(stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[1],stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[0]),xy=(0.05,0.8),xycoords=\"axes fraction\")\n",
    "#make the legend in the middle right of the plot\n",
    "ax.legend(loc=\"center left\")\n",
    "plt.show()\n",
    "print(np.max(sizes_hupa*globals[\"confocal_pixel_size\"]))\n",
    "print(np.min(sizes_hupa*globals[\"confocal_pixel_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean and standard deviation of the hupa and rpoc blobs\n",
    "print(\"HupA: mean = {:.2f} nm, std = {:.2f} nm\".format(np.mean(sizes_hupa*globals[\"confocal_pixel_size\"]),np.std(sizes_hupa*globals[\"confocal_pixel_size\"])))\n",
    "print(\"rpoC: mean = {:.2f} nm, std = {:.2f} nm\".format(np.mean(sizes_rpoc*globals[\"confocal_pixel_size\"]),np.std(sizes_rpoc*globals[\"confocal_pixel_size\"])))\n",
    "#do the same for the aml rpoc blobs\n",
    "print(\"AML's rpoC: mean = {:.2f} nm, std = {:.2f} nm\".format(np.mean(sizes_aml_rpoc*globals[\"confocal_pixel_size\"]),np.std(sizes_aml_rpoc*globals[\"confocal_pixel_size\"])))\n",
    "#find the p value and the statistic of the ks test\n",
    "print(\"K-S Test: p_val = {:.2e}, D = {:.2f}\".format(stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[1],stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[0]))\n",
    "\n",
    "#test if the two rpoc distributions are from the same distribution\n",
    "print(\"K-S Test for rpoC and AML's rpoC: p_val = {:.2e}, D = {:.2f}\".format(stats.ks_2samp(sizes_rpoc*globals[\"confocal_pixel_size\"],sizes_aml_rpoc*globals[\"confocal_pixel_size\"])[1],stats.ks_2samp(sizes_rpoc*globals[\"confocal_pixel_size\"],sizes_aml_rpoc*globals[\"confocal_pixel_size\"])[0]))\n",
    "\n",
    "#test if AML's rpoC and HupA are from the same distribution\n",
    "print(\"K-S Test for AML's rpoC and HupA: p_val = {:.2e}, D = {:.2f}\".format(stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_aml_rpoc*globals[\"confocal_pixel_size\"])[1],stats.ks_2samp(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_aml_rpoc*globals[\"confocal_pixel_size\"])[0]))\n",
    "\n",
    "#Statistics \n",
    "#perform a wilcoxon rank sum test on the hupa and rpoc blobs\n",
    "print(\"Wilcoxon Rank Sum Test: p_val = {:.2e}, W = {:.2f}\".format(stats.ranksums(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[1],stats.ranksums(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[0]))\n",
    "#perform a mann whitney u test on the hupa and rpoc blobs\n",
    "print(\"Mann Whitney U Test: p_val = {:.2e}, U = {:.2f}\".format(stats.mannwhitneyu(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[1],stats.mannwhitneyu(sizes_hupa*globals[\"confocal_pixel_size\"],sizes_rpoc*globals[\"confocal_pixel_size\"])[0]))\n",
    "\n",
    "#check if the hupa and rpoc blobs are normally distributed\n",
    "print(\"HupA: normal = {}, skew = {:.2f}, kurtosis = {:.2f}\".format(stats.normaltest(sizes_hupa*globals[\"confocal_pixel_size\"])[1]>0.05,stats.skew(sizes_hupa*globals[\"confocal_pixel_size\"]),stats.kurtosis(sizes_hupa*globals[\"confocal_pixel_size\"])))\n",
    "print(\"rpoC: normal = {}, skew = {:.2f}, kurtosis = {:.2f}\".format(stats.normaltest(sizes_rpoc*globals[\"confocal_pixel_size\"])[1]>0.05,stats.skew(sizes_rpoc*globals[\"confocal_pixel_size\"]),stats.kurtosis(sizes_rpoc*globals[\"confocal_pixel_size\"])))\n",
    "#check if the aml rpoc blobs are normally distributed\n",
    "print(\"AML's rpoC: normal = {}, skew = {:.2f}, kurtosis = {:.2f}\".format(stats.normaltest(sizes_aml_rpoc*globals[\"confocal_pixel_size\"])[1]>0.05,stats.skew(sizes_aml_rpoc*globals[\"confocal_pixel_size\"]),stats.kurtosis(sizes_aml_rpoc*globals[\"confocal_pixel_size\"])))\n",
    "\n",
    "#find the number of blobs in the hupa and rpoc files\n",
    "print(\"HupA: number of blobs = {}\".format(len(sizes_hupa)))\n",
    "print(\"rpoC: number of blobs = {}\".format(len(sizes_rpoc)))\n",
    "\n",
    "#find the number of blobs in each file\n",
    "print(\"HupA: number of blobs per file = {}\".format([len(i) for i in blobs_hupa]))\n",
    "print(\"rpoC: number of blobs per file = {}\".format([len(i) for i in blobs_rpoc]))\n",
    "\n",
    "#create a QQ plot for both the hupa and rpoc blobs to check if they are normally distributed. Do this on the same plot\n",
    "plt.clf()\n",
    "stats.probplot(sizes_hupa*globals[\"confocal_pixel_size\"],dist=\"norm\",plot=plt)\n",
    "stats.probplot(sizes_rpoc*globals[\"confocal_pixel_size\"],dist=\"norm\",plot=plt)\n",
    "#do this for the aml rpoc blobs\n",
    "stats.probplot(sizes_aml_rpoc*globals[\"confocal_pixel_size\"],dist=\"norm\",plot=plt)\n",
    "#annotate the two datasets with rpoc and hupa labels, make the text bold and readable at a distance\n",
    "plt.annotate(\"HupA\",xy=(0.05,0.35),xycoords=\"axes fraction\",fontweight=\"bold\",fontsize=16)\n",
    "plt.annotate(\"rpoC\",xy=(0.05,0.18),xycoords=\"axes fraction\",fontweight=\"bold\",fontsize=16)\n",
    "plt.annotate(\"AML's rpoC\",xy=(0.05,0.01),xycoords=\"axes fraction\",fontweight=\"bold\",fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection on specific image just to see what it looks like\n",
    "#image path\n",
    "path = \"/Users/baljyot/Desktop/mid_GC.tif\"\n",
    "#open this image using function from import_functions.py\n",
    "\n",
    "#make a maximum projection of the image\n",
    "#max_proj = np.max(io.imread(path),axis=0)\n",
    "#img = max_proj\n",
    "#create a blob detector object\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":1e-2,\n",
    "                \"min_sigma\":2./np.sqrt(2),\n",
    "                \"max_sigma\":50./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":False}\n",
    "fitting_args = {\"mask_size\":3,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":np.mean,\n",
    "                \"residual_func\":residuals_gaus2d,\n",
    "                \"sigma_range\":2}\n",
    "\n",
    "img = np.array(import_functions.invert_I16u(io.imread(path)))\n",
    "\n",
    "blob_detector = blob_detection(path=img,**detection_args)\n",
    "blob_detector._update_fitting_parameters(kwargs=fitting_args)\n",
    "#detect blobs\n",
    "c = blob_detector.detection(type=\"bp\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(img,cmap=\"gray\")\n",
    "print(c)\n",
    "for i in c:\n",
    "    cir = plt.Circle((i[1],i[0]),i[2],fill = False)\n",
    "    ax.add_artist(cir)\n",
    "    cir = plt.Circle((i[1],i[0]),0.1,fill = True)\n",
    "    ax.add_artist(cir)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19) (19, 19) (19, 19)\n",
      "(20, 19) (20, 19) (20, 20)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,20) (20,19) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb#Y130sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m blob_detector\u001b[39m.\u001b[39m_update_fitting_parameters(kwargs\u001b[39m=\u001b[39mfitting_args)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb#Y130sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#detect blobs\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb#Y130sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m c \u001b[39m=\u001b[39m blob_detector\u001b[39m.\u001b[39;49mdetection(\u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb#Y130sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/Density_Map.ipynb#Y130sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot()\n",
      "File \u001b[0;32m~/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/src/helpers/blob_detection.py:204\u001b[0m, in \u001b[0;36mblob_detection.detection\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    202\u001b[0m \t\u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(blobs) \u001b[39m#blobs returns array of size 3 tuples (x,y,radius) defining the circle defining the spot \u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbp\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[0;32m--> 204\u001b[0m \tblobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblob_logv2(file,threshold \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold,min_sigma \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_sigma,max_sigma \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_sigma,num_sigma \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_sigma, overlap \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverlap,log_scale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_scale)\n\u001b[1;32m    205\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    207\u001b[0m \t\tblobs[\u001b[39m\"\u001b[39m\u001b[39mFitted\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m2\u001b[39m:]\u001b[39m*\u001b[39m\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m) \u001b[39m#converting the standard deviation of the gaussian fit to radius of the circle \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/src/helpers/blob_detection.py:467\u001b[0m, in \u001b[0;36mblob_detection.blob_logv2\u001b[0;34m(self, image, min_sigma, max_sigma, num_sigma, threshold, overlap, log_scale, exclude_border, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m blobs_pruned,sigma_indx_pruned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prune_blobs(\n\u001b[1;32m    461\u001b[0m \tlm, overlap,\n\u001b[1;32m    462\u001b[0m \tsigma_dim\u001b[39m=\u001b[39msigma_dim,\n\u001b[1;32m    463\u001b[0m \tmax_lap \u001b[39m=\u001b[39m max_lap,\n\u001b[1;32m    464\u001b[0m \tsigma_indx \u001b[39m=\u001b[39m local_max_sigma_indx)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitting_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfitting_image\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mOriginal\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOriginal\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 467\u001b[0m \tfit_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_mask(\n\u001b[1;32m    468\u001b[0m \t\timage2,blobs_pruned,\n\u001b[1;32m    469\u001b[0m \t\tsize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitting_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmask_size\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m5\u001b[39;49m),\n\u001b[1;32m    470\u001b[0m \t\tsigma_indx\u001b[39m=\u001b[39;49msigma_indx_pruned)\n\u001b[1;32m    471\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m \tfit_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_mask(\n\u001b[1;32m    473\u001b[0m \t\timage_cube,blobs_pruned,\n\u001b[1;32m    474\u001b[0m \t\tsize\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitting_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmask_size\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m5\u001b[39m),\n\u001b[1;32m    475\u001b[0m \t\tsigma_indx\u001b[39m=\u001b[39msigma_indx_pruned)\n",
      "File \u001b[0;32m~/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/src/helpers/blob_detection.py:577\u001b[0m, in \u001b[0;36mblob_detection._create_mask\u001b[0;34m(self, img, coords, size, sigma_indx)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39m#initialize the fitter\u001b[39;00m\n\u001b[1;32m    571\u001b[0m initials\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitalize_2dgaus(height \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(view)\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmin(view),\\\n\u001b[1;32m    572\u001b[0m \t\t\t\tcentroid_x \u001b[39m=\u001b[39m val[\u001b[39m0\u001b[39m],\\\n\u001b[1;32m    573\u001b[0m \t\t\t\tcentroid_y \u001b[39m=\u001b[39m val[\u001b[39m1\u001b[39m],\\\n\u001b[1;32m    574\u001b[0m \t\t\t\tsigma_x \u001b[39m=\u001b[39m val[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\\\n\u001b[1;32m    575\u001b[0m \t\t\t\tsigma_y \u001b[39m=\u001b[39m val[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\\\n\u001b[1;32m    576\u001b[0m \t\t\t\tbackground \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmin(view))\t\t\n\u001b[0;32m--> 577\u001b[0m fit \u001b[39m=\u001b[39m minimize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitting_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mresidual_func\u001b[39;49m\u001b[39m\"\u001b[39;49m,residuals_gaus2d), initials, args\u001b[39m=\u001b[39;49m(x, y, view),method \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitting_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mfit_method\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mleast_squares\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    578\u001b[0m fit_objects\u001b[39m.\u001b[39mappend(fit)\n\u001b[1;32m    580\u001b[0m \u001b[39m#check fit\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/lmfit/minimizer.py:2583\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fcn, params, method, args, kws, iter_cb, scale_covar, nan_policy, reduce_fcn, calc_covar, max_nfev, **fit_kws)\u001b[0m\n\u001b[1;32m   2443\u001b[0m \u001b[39m\"\"\"Perform the minimization of the objective function.\u001b[39;00m\n\u001b[1;32m   2444\u001b[0m \n\u001b[1;32m   2445\u001b[0m \u001b[39mThe minimize function takes an objective function to be minimized,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2577\u001b[0m \n\u001b[1;32m   2578\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m fitter \u001b[39m=\u001b[39m Minimizer(fcn, params, fcn_args\u001b[39m=\u001b[39margs, fcn_kws\u001b[39m=\u001b[39mkws,\n\u001b[1;32m   2580\u001b[0m                    iter_cb\u001b[39m=\u001b[39miter_cb, scale_covar\u001b[39m=\u001b[39mscale_covar,\n\u001b[1;32m   2581\u001b[0m                    nan_policy\u001b[39m=\u001b[39mnan_policy, reduce_fcn\u001b[39m=\u001b[39mreduce_fcn,\n\u001b[1;32m   2582\u001b[0m                    calc_covar\u001b[39m=\u001b[39mcalc_covar, max_nfev\u001b[39m=\u001b[39mmax_nfev, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kws)\n\u001b[0;32m-> 2583\u001b[0m \u001b[39mreturn\u001b[39;00m fitter\u001b[39m.\u001b[39;49mminimize(method\u001b[39m=\u001b[39;49mmethod)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/lmfit/minimizer.py:2352\u001b[0m, in \u001b[0;36mMinimizer.minimize\u001b[0;34m(self, method, params, **kws)\u001b[0m\n\u001b[1;32m   2349\u001b[0m         \u001b[39mif\u001b[39;00m (key\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstartswith(user_method) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   2350\u001b[0m                 val\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstartswith(user_method)):\n\u001b[1;32m   2351\u001b[0m             kwargs[\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m val\n\u001b[0;32m-> 2352\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/lmfit/minimizer.py:1574\u001b[0m, in \u001b[0;36mMinimizer.least_squares\u001b[0;34m(self, params, max_nfev, **kws)\u001b[0m\n\u001b[1;32m   1572\u001b[0m result\u001b[39m.\u001b[39mcall_kws \u001b[39m=\u001b[39m kws\n\u001b[1;32m   1573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m     ret \u001b[39m=\u001b[39m least_squares(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__residual, start_vals,\n\u001b[1;32m   1575\u001b[0m                         bounds\u001b[39m=\u001b[39;49m(lower_bounds, upper_bounds),\n\u001b[1;32m   1576\u001b[0m                         kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(apply_bounds_transformation\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1577\u001b[0m                         max_nfev\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_nfev, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkws)\n\u001b[1;32m   1578\u001b[0m     result\u001b[39m.\u001b[39mresidual \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mfun\n\u001b[1;32m   1579\u001b[0m \u001b[39mexcept\u001b[39;00m AbortFitException:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/scipy/optimize/_lsq/least_squares.py:820\u001b[0m, in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    818\u001b[0m     x0 \u001b[39m=\u001b[39m make_strictly_feasible(x0, lb, ub)\n\u001b[0;32m--> 820\u001b[0m f0 \u001b[39m=\u001b[39m fun_wrapped(x0)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m f0\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    823\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` must return at most 1-d array_like. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mf0.shape: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(f0\u001b[39m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/scipy/optimize/_lsq/least_squares.py:815\u001b[0m, in \u001b[0;36mleast_squares.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/lmfit/minimizer.py:587\u001b[0m, in \u001b[0;36mMinimizer.__residual\u001b[0;34m(self, fvars, apply_bounds_transformation)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult\u001b[39m.\u001b[39msuccess \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[39mraise\u001b[39;00m AbortFitException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfit aborted: too many function evaluations \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_nfev\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 587\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muserfcn(params, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muserargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muserkws)\n\u001b[1;32m    589\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_cb):\n\u001b[1;32m    590\u001b[0m     abort \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_cb(params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult\u001b[39m.\u001b[39mnfev, out,\n\u001b[1;32m    591\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muserargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muserkws)\n",
      "File \u001b[0;32m~/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/Scripts/src/helpers/blob_detection.py:724\u001b[0m, in \u001b[0;36mresiduals_gaus2d\u001b[0;34m(p, x, y, z, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m sigma_y \u001b[39m=\u001b[39m p[\u001b[39m\"\u001b[39m\u001b[39msigma_y\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    723\u001b[0m offset \u001b[39m=\u001b[39m p[\u001b[39m\"\u001b[39m\u001b[39mbackground\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 724\u001b[0m \u001b[39mreturn\u001b[39;00m (z \u001b[39m-\u001b[39;49m gaussian2D(x\u001b[39m=\u001b[39;49mx,\\\n\u001b[1;32m    725\u001b[0m \t\t\t\t\ty\u001b[39m=\u001b[39;49my,\\\n\u001b[1;32m    726\u001b[0m \t\t\t\t\tcen_x\u001b[39m=\u001b[39;49mcen_x,\\\n\u001b[1;32m    727\u001b[0m \t\t\t\t\tcen_y\u001b[39m=\u001b[39;49mcen_y,\\\n\u001b[1;32m    728\u001b[0m \t\t\t\t\tsig_x\u001b[39m=\u001b[39;49msigma_x,\\\n\u001b[1;32m    729\u001b[0m \t\t\t\t\tsig_y\u001b[39m=\u001b[39;49msigma_y,\\\n\u001b[1;32m    730\u001b[0m \t\t\t\t\toffset\u001b[39m=\u001b[39;49moffset,\\\n\u001b[1;32m    731\u001b[0m \t\t\t\t\theight\u001b[39m=\u001b[39;49mheight,\\\n\u001b[1;32m    732\u001b[0m \t\t\t\t\tkwargs\u001b[39m=\u001b[39;49mkwargs))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,20) (20,19) "
     ]
    }
   ],
   "source": [
    "#################### fixing for peng's issues\n",
    "#detection on specific image just to see what it looks like\n",
    "#image path\n",
    "path = \"/Users/baljyot/Desktop/mid_GC.tif\"\n",
    "#open this image using function from import_functions.py\n",
    "\n",
    "#make a maximum projection of the image\n",
    "#max_proj = np.max(io.imread(path),axis=0)\n",
    "#img = max_proj\n",
    "#create a blob detector object\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":1e-2,\n",
    "                \"min_sigma\":2./np.sqrt(2),\n",
    "                \"max_sigma\":50./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":True}\n",
    "fitting_args = {\"mask_size\":3,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":None,\n",
    "                \"residual_func\":residuals_gaus2d,\n",
    "                \"sigma_range\":2,\n",
    "                \"centroid_range\":1}\n",
    "\n",
    "img = io.imread(path)#np.array(import_functions.invert_I16u(io.imread(path)))\n",
    "\n",
    "blob_detector = blob_detection(path=img,**detection_args)\n",
    "blob_detector._update_fitting_parameters(kwargs=fitting_args)\n",
    "#detect blobs\n",
    "c = blob_detector.detection(type=\"bp\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(img,cmap=\"gray\")\n",
    "print(c)\n",
    "for i in c[\"Fitted\"]:\n",
    "    cir = plt.Circle((i[1],i[0]),i[2],fill = False)\n",
    "    ax.add_artist(cir)\n",
    "    cir = plt.Circle((i[1],i[0]),0.1,fill = True)\n",
    "    ax.add_artist(cir)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trajectory from FBM and then use the msd analysis to find the alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "track = fbm_utility.get_fbm_sample(l=1,h=0.5,d=2,n=15)\n",
    "x,y = track[1][0]*np.sqrt(1),track[1][1]*np.sqrt(1)\n",
    "#find the msd of the track for different time intervals\n",
    "msd = []\n",
    "for i in range(1,1000):\n",
    "    msd.append(np.mean((np.diff(x[::i]))**2+(np.diff(y[::i]))**2))\n",
    "plt.plot(range(1,1000),msd)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "sim = simulate_foci.sim_foci(max_x = 50,\n",
    "                            min_x = 0,\n",
    "                            radius = 5,\n",
    "                            center = [25.,25.],\n",
    "                            total_points = 100,\n",
    "                            density_dif = 100000000.0,\n",
    "                            pdf = simulate_foci.tophat_function_2d)\n",
    "sim.uniform_uniform_blob = True\n",
    "sim.psf_sigma = 0.82\n",
    "map,sim_xy = sim.simulate_point()\n",
    "map = np.array(map)\n",
    "#map += np.random.rand(*np.shape(map))*np.max(map)/100\n",
    "\n",
    "x,y = np.meshgrid(np.arange(0,50),np.arange(0,50))\n",
    "# fig = plt.figure()\n",
    "# # ax = plt.axes(projection='3d')\n",
    "# # ax.plot_wireframe(x,y,map)\n",
    "# # ax.set_xlim((10,30))\n",
    "# # ax.set_ylim((10,30))\n",
    "# # plt.show()\n",
    "def dim_dif_total(radi,points):\n",
    "    maps = []\n",
    "    for i in points:\n",
    "        sim = simulate_foci.sim_foci(max_x = 50,\n",
    "                            min_x = 0,\n",
    "                            radius = radi,\n",
    "                            center = [25.,25.],\n",
    "                            total_points = int(i),\n",
    "                            density_dif = 100000000.0,\n",
    "                            pdf = simulate_foci.tophat_function_2d)\n",
    "        sim.uniform_uniform_blob = True\n",
    "        sim.psf_sigma = 0.82\n",
    "        map,sim_xy = sim.simulate_point()\n",
    "        maps.append(np.array(map))\n",
    "    return maps\n",
    "# maps = dim_dif_total(3,[1e1])\n",
    "# plt.clf()\n",
    "# def normalize_2d(a):\n",
    "#     row_sums = a.sum(axis=1)\n",
    "#     new_matrix = a / row_sums[:, np.newaxis]\n",
    "#     return new_matrix\n",
    "# for i in maps:\n",
    "#     plt.contour(x,normalize_2d(i),y,label = \"points = {0}\".format(i))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "a = simulate_foci.generate_sphere_points(200,[1,1,1],10)\n",
    "b = simulate_foci.generate_radial_points(200,[1,1],10)\n",
    "fig,ax = plt.subplots(2,2,sharex=True,sharey=True)\n",
    "#make the x and y axis for each subplot the same aspect ratio\n",
    "ax[0,0].set_aspect('equal')\n",
    "ax[1,0].set_aspect('equal')\n",
    "ax[0,1].set_aspect('equal')\n",
    "ax[1,1].set_aspect('equal')\n",
    "\n",
    "ax[0,0].plot(a[:,0],a[:,1],'o',markersize=1)\n",
    "ax[1,0].plot(b[:,0],b[:,1],'o',markersize=1)\n",
    "#on the top right plot, plot the density of the points over the whole figure\n",
    "#first, make a histogram of the points\n",
    "hist, xedges, yedges = np.histogram2d(a[:,0],a[:,1],bins=100)\n",
    "#make a meshgrid of the x and y edges\n",
    "x,y = np.meshgrid(xedges,yedges)\n",
    "#plot the histogram as a contour plot\n",
    "ax[0,1].contour(x[1:,1:],y[1:,1:],hist)\n",
    "#on the bottom right plot, plot the density of the points over the whole figure\n",
    "#first, make a histogram of the points\n",
    "hist, xedges, yedges = np.histogram2d(b[:,0],b[:,1],bins=100)\n",
    "#make a meshgrid of the x and y edges\n",
    "x,y = np.meshgrid(xedges,yedges)\n",
    "#plot the histogram as a contour plot\n",
    "ax[1,1].contour(x[1:,1:],y[1:,1:],hist)\n",
    "#add the circles to the top left plot and the bottom left plot\n",
    "cir = Circle((1,1),10,fill = False)\n",
    "ax[0,0].add_patch(cir)\n",
    "cir2 = Circle((1,1),10,fill = False)\n",
    "ax[1,0].add_patch(cir2)\n",
    "#add the circles to the top right plot and hte bottom right plot\n",
    "cir = Circle((1,1),10,fill = False)\n",
    "ax[0,1].add_patch(cir)\n",
    "cir2 = Circle((1,1),10,fill = False)\n",
    "ax[1,1].add_patch(cir2)\n",
    "#title the plots\n",
    "ax[0,0].set_title(\"Uniform points in a sphere (projection to 2D)\") \n",
    "ax[1,0].set_title(\"Uniform points in a circle\")\n",
    "ax[0,1].set_title(\"Density of points in a sphere (projection to 2D)\")   \n",
    "ax[1,1].set_title(\"Density of points in a circle\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim = simulate_foci.sim_foci(max_x = 50,\n",
    "                            min_x = 0,\n",
    "                            radius = 2,\n",
    "                            center = [25.,25.],\n",
    "                            total_points = 100,\n",
    "                            density_dif = 100000000.0,\n",
    "                            pdf = simulate_foci.tophat_function_2d,\n",
    "                            point_intensity = 40,\n",
    "                            projection_frames = 1000)\n",
    "sim.uniform_blob = True\n",
    "sim.psf_sigma = 0.82\n",
    "sim.base_noise = 140\n",
    "map,sim_xy = sim.simulate_point(generator = None)\n",
    "\n",
    "map = np.array(map)\n",
    "b = blob_detection(path = map,\\\n",
    "                    median= False,\\\n",
    "                    threshold= 1e3, \\\n",
    "                    min_sigma= 1/np.sqrt(2), \\\n",
    "                    max_sigma = 10/np.sqrt(2), \\\n",
    "                    num_sigma= 1000, \\\n",
    "                    overlap = 0, \\\n",
    "                    logscale=False,\n",
    "                    verbose=True)\n",
    "b._update_fitting_parameters(kwargs={\"mask_size\":3,\n",
    "                            \"plot_fit\":False,\n",
    "                            \"fitting_image\":\"Original\",\n",
    "                            \"radius_func\":None,\n",
    "                            \"sigma_range\":0.25,\n",
    "                            \"centroid_range\":0.5})\n",
    "c = b.detection(type = \"bp\")\n",
    "#print(c)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(map,cmap=\"gray\")\n",
    "for i in c[\"Fitted\"]:\n",
    "    cir = plt.Circle((i[0],i[1]),i[2],fill = False, edgecolor = \"green\")\n",
    "    ax.add_artist(cir)\n",
    "    ax.plot(i[0],i[1],\"o\",color = \"green\",markersize = 2,label = \"Fitted Blob Center and Radius\")\n",
    "# for i in sim_xy:\n",
    "#     ax.plot(i[0],i[1],\"o\",color = \"red\",markersize = 2,label = \"Simulated Blob Center\")\n",
    "#add a legend for the circle\n",
    "\n",
    "\n",
    "cir = plt.Circle((sim.center[0],sim.center[1]),sim.radius,fill = False,edgecolor = \"Red\")\n",
    "ax.plot(sim.center[0],sim.center[1],\"o\",color = \"red\",markersize = 2,label = \"Simulated Blob Center and Radius\")\n",
    "plt.legend()\n",
    "\n",
    "ax.add_artist(cir)\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(bin_img(map,bin=2,operation='mean'),cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isotropic residual gaussain\n",
    "def iso_gaus(p,x,y,z):\n",
    "    p[\"sigma_x\"] = p[\"sigma_y\"]\n",
    "    return residuals_gaus2d(p,x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii = np.linspace(0.5,4.5,20)\n",
    "sim_args = {\"max_x\":50,\n",
    "            \"min_x\":0,\n",
    "            \"center\":[25,25],\n",
    "            \"total_points\":1,\n",
    "            \"density_dif\":1e7,\n",
    "            \"pdf\":simulate_foci.tophat_function_2d,\n",
    "            \"uniform\":True,\n",
    "            \"psf_sigma\":0.82}\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":1e-2,\n",
    "                \"min_sigma\":1./np.sqrt(2),\n",
    "                \"max_sigma\":10./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":True}\n",
    "fitting_args = {\"mask_size\":5,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":np.mean,\n",
    "                \"residual_func\":residuals_gaus2d,\n",
    "                \"sigma_range\":2}\n",
    "track_args = {\"track_length_mean\":10,\n",
    "            \"track_type\":\"fbm\",\n",
    "            \"track_hurst\":0.2,\n",
    "            \"track_distribution\":\"uniform\",\n",
    "            \"diffusion_coefficient\":1e-2}\n",
    "a = simulate_foci.sim_focii(radii=radii,repeats=5,detection_kwargs=detection_args,sim_kwargs=sim_args,fitting_parm=fitting_args,track_parm=track_args)\n",
    "a.use_points = True\n",
    "point_density = 10\n",
    "c = a.radius_analysis(point_density=point_density)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_rp_rad = 206.2 #nm\n",
    "max_rp_rad = 375.0 #nm\n",
    "\n",
    "min_ll_rad = 160.7 #nm\n",
    "max_ll_rad = 252.0 #nm\n",
    "\n",
    "min_hupa_rad = 240 #nm\n",
    "max_hupa_rad = 720 #nm\n",
    "\n",
    "\n",
    "\n",
    "min_rad = np.min(np.asarray(radii)*globals[\"olympus_pixel_size\"])\n",
    "max_rad = np.max(np.asarray(radii)*globals[\"olympus_pixel_size\"])\n",
    "\n",
    "plt.clf()\n",
    "plt.errorbar(np.asarray(radii)*globals[\"olympus_pixel_size\"],globals[\"olympus_pixel_size\"]*np.asarray(c[\"fit_mean\"]),yerr=globals[\"olympus_pixel_size\"]*np.asarray(c[\"fit_stds\"]),label = \"Gaussian Fit\")\n",
    "plt.errorbar(np.asarray(radii)*globals[\"olympus_pixel_size\"],globals[\"olympus_pixel_size\"]*np.asarray(c[\"sig_mean\"]),yerr=globals[\"olympus_pixel_size\"]*np.asarray(c[\"sig_std\"]), label = \"Scale-Space\")\n",
    "#plt.plot(np.asarray(radii)*globals[pixel_size],np.asarray(radii)*globals[pixel_size],label = \"True\")\n",
    "#plt.plot(np.linspace(0,10,100),np.linspace(0,10,100),'r-')\n",
    "# plt.ylim((0,4)) \n",
    "# plt.xlim((0,4))\n",
    "\n",
    "plt.ylabel(\"Found Radius (nm)\")\n",
    "plt.xlabel(\"Simulated Radius (nm)\")\n",
    "plt.hlines([min_rp_rad,max_rp_rad],min_rad,max_rad)\n",
    "plt.fill_between([min_rad,max_rad],[min_rp_rad,min_rp_rad],[max_rp_rad,max_rp_rad],color = 'red', alpha=0.2,label = \"rp_ez Radii Spread\")\n",
    "plt.hlines([min_ll_rad,max_ll_rad],min_rad,max_rad)\n",
    "plt.fill_between([min_rad,max_rad],[min_ll_rad,min_ll_rad],[max_ll_rad,max_ll_rad],color = 'green', alpha=0.2,label = \"ll_ez Radii Spread\")\n",
    "\n",
    "#make the vertial lines again for the hupa\n",
    "plt.hlines([min_hupa_rad,max_hupa_rad],min_rad,max_rad)\n",
    "plt.fill_between([min_rad,max_rad],[min_hupa_rad,min_hupa_rad],[max_hupa_rad,max_hupa_rad],color = 'blue', alpha=0.2,label = \"hupa Radii Spread\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.errorbar(np.asarray(radii)*globals[\"olympus_pixel_size\"],100*np.abs(np.asarray(c[\"fit_mean\"])-np.asarray(radii))/np.asarray(radii),yerr=100*np.asarray(c[\"fit_stds\"])/np.asarray(radii),label = \"Gaussian Fit\")\n",
    "plt.errorbar(np.asarray(radii)*globals[\"olympus_pixel_size\"],100*np.abs(np.asarray(c[\"sig_mean\"])-np.asarray(radii))/np.asarray(radii),yerr=100*np.asarray(c[\"sig_std\"])/np.asarray(radii),label = \"Space-Space\")\n",
    "#plt.plot(np.linspace(0,10,100),np.linspace(0,10,100),'r-')\n",
    "#print(radius/np.sqrt(2),found_radius,std_radius)\n",
    "# plt.ylim((0,4))\n",
    "# plt.xlim((0,4))\n",
    "plt.ylabel(\"Percent Error\")\n",
    "plt.xlabel(\"Simulated Radius (nm)\")\n",
    "\n",
    "plt.axvspan(min_rp_rad, max_rp_rad, alpha=0.2, color='red',label = \"rp_ez_spread\")\n",
    "plt.axvspan(min_ll_rad, max_ll_rad, alpha=0.2, color='green',label = \"ll_ez_spread\")\n",
    "#do the same for hupa\n",
    "plt.axvspan(min_hupa_rad, max_hupa_rad, alpha=0.2, color='blue',label = \"hupa_spread\")\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#redo this plot and make it look nice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.errorbar((np.asarray(radii))*globals[\"olympus_pixel_size\"],(np.asarray(c[\"fit_mean\"])-np.asarray(radii))*globals[\"olympus_pixel_size\"],yerr=globals[\"olympus_pixel_size\"]*(np.asarray(c[\"fit_stds\"])),label = \"Gaussian Fit\")\n",
    "plt.errorbar((np.asarray(radii))*globals[\"olympus_pixel_size\"],(np.asarray(c[\"sig_mean\"])-np.asarray(radii))*globals[\"olympus_pixel_size\"],yerr=globals[\"olympus_pixel_size\"]*(np.asarray(c[\"sig_std\"])),label = \"Scale-Space\")\n",
    "#plt.plot(np.linspace(0,10,100),np.linspace(0,10,100),'r-')\n",
    "#print(radius/np.sqrt(2),found_radius,globals[pixel_size]*std_radius)\n",
    "# plt.ylim((0,4))\n",
    "# plt.xlim((0,4))\n",
    "plt.legend()\n",
    "#plt.yscale(\"log\")\n",
    "plt.ylabel(\"Error from True (nm)\")\n",
    "plt.xlabel(\"Simulated Radius (nm)\")\n",
    "plt.axvspan(min_rp_rad, max_rp_rad, alpha=0.2, color='red')\n",
    "plt.axvspan(min_ll_rad, max_ll_rad, alpha=0.2, color='green')\n",
    "#do the same for hupa\n",
    "plt.axvspan(min_hupa_rad, max_hupa_rad, alpha=0.2, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## changing alpha values for tracks used, constant total_points\n",
    "radii = np.linspace(0.5,4.5,20)\n",
    "sim_args = {\"max_x\":50,\n",
    "            \"min_x\":0,\n",
    "            \"center\":[25,25],\n",
    "            \"total_points\":500,\n",
    "            \"density_dif\":1e7,\n",
    "            \"pdf\":simulate_foci.tophat_function_2d,\n",
    "            \"uniform\":True,\n",
    "            \"psf_sigma\":0.82}\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":1e-2,\n",
    "                \"min_sigma\":1./np.sqrt(2),\n",
    "                \"max_sigma\":10./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":True}\n",
    "fitting_args = {\"mask_size\":5,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":squared_mean_difference,\n",
    "                \"residual_func\":iso_gaus,\n",
    "                \"sigma_range\":2}\n",
    "track_args = {\"track_length_mean\":10,\n",
    "            \"track_type\":\"fbm\",\n",
    "            \"track_hurst\":0.35,\n",
    "            \"track_distribution\":\"uniform\",\n",
    "            \"diffusion_coefficient\":1e-2}\n",
    "\n",
    "#hurst values from 0.15 to 0.5\n",
    "hursts = np.linspace(0.15,0.5,10)\n",
    "data_store = {}\n",
    "\n",
    "for i in hursts:\n",
    "    track_args[\"track_hurst\"] = i\n",
    "    a = simulate_foci.sim_focii(radii=radii,repeats=3,detection_kwargs=detection_args,sim_kwargs=sim_args,fitting_parm=fitting_args,track_parm=track_args)\n",
    "    a.use_points=False\n",
    "    data_store[i] = a.total_points_radius_analysis(total_points=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results of the hurst analysis, the hurst value vs percent error for each radii\n",
    "plt.clf()\n",
    "#make a figure with one subplot\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "for i,c in data_store.items():\n",
    "    #make the label with the hurst to the closest decimal\n",
    "    ax.errorbar(np.asarray(radii)*globals[\"olympus_pixel_size\"],100*np.abs(np.asarray(c[\"sig_mean\"])-np.asarray(radii))/np.asarray(radii),yerr=100*np.asarray(c[\"sig_std\"])/np.asarray(radii),label = \"Hurst = \"+str(np.around(i,3)))\n",
    "ax.axvspan(min_rp_rad, max_rp_rad, alpha=0.2, color='red',label = \"rp_ez_spread\")\n",
    "ax.axvspan(min_ll_rad, max_ll_rad, alpha=0.2, color='green',label = \"ll_ez_spread\")\n",
    "#do the same for hupa\n",
    "ax.axvspan(min_hupa_rad, max_hupa_rad, alpha=0.2, color='blue',label = \"hupa_spread\")\n",
    "ax.set_ylabel(\"Percent Error\")\n",
    "ax.set_xlabel(\"Simulated Radius (nm)\")\n",
    "ax.set_title(\"Percent Error vs Simulated Radius for Different Hurst Values \\n Using 200 Total Points per Blob\")\n",
    "ax.legend()\n",
    "#make the plot look nice\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## changing points simulated for each radius using tracks instead of random points\n",
    "radii = np.linspace(0.5,4.5,10)\n",
    "sim_args = {\"max_x\":50,\n",
    "            \"min_x\":0,\n",
    "            \"center\":[25,25],\n",
    "            \"total_points\":500,\n",
    "            \"density_dif\":1e7,\n",
    "            \"pdf\":simulate_foci.tophat_function_2d,\n",
    "            \"uniform\":True,\n",
    "            \"psf_sigma\":0.82}\n",
    "detection_args = {\"median\":False,\n",
    "                \"threshold\":1e-2,\n",
    "                \"min_sigma\":1./np.sqrt(2),\n",
    "                \"max_sigma\":10./np.sqrt(2),\n",
    "                \"num_sigma\":200,\n",
    "                \"overlap\":0,\n",
    "                \"logscale\":False,\n",
    "                \"verbose\":True}\n",
    "fitting_args = {\"mask_size\":5,\n",
    "                \"plot_fit\":False,\n",
    "                \"fitting_image\":\"Original\",\n",
    "                \"radius_func\":squared_mean_difference,\n",
    "                \"residual_func\":iso_gaus,\n",
    "                \"sigma_range\":2}\n",
    "track_args = {\"track_length_mean\":10,\n",
    "            \"track_type\":\"fbm\",\n",
    "            \"track_hurst\":0.35,\n",
    "            \"track_distribution\":\"uniform\",\n",
    "            \"diffusion_coefficient\":1e-2}\n",
    "a = simulate_foci.sim_focii(radii=radii,repeats=3,detection_kwargs=detection_args,sim_kwargs=sim_args,fitting_parm=fitting_args,track_parm=track_args)\n",
    "a.use_points=False\n",
    "total_points = np.arange(100,901,200) + 1\n",
    "data_store = {}\n",
    "for i in total_points:\n",
    "    data_store[i] = a.total_points_radius_analysis(total_points=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i,c in data_store.items():\n",
    "    #plt.clf()\n",
    "    #plt.errorbar(np.asarray(radii)*globals[pixel_size],100*np.abs(np.asarray(c[\"fit_mean\"])-np.asarray(radii))/np.asarray(radii),yerr=100*np.asarray(c[\"fit_stds\"])/np.asarray(radii),label = \"Gaussian Fit Points:{0}\".format(i))\n",
    "    plt.errorbar(np.asarray(radii)*globals[\"confocal_pixel_size\"],100*np.abs(np.asarray(c[\"sig_mean\"])-np.asarray(radii))/np.asarray(radii),yerr=100*np.asarray(c[\"sig_std\"])/np.asarray(radii),label = \"Space-Space Points:{0}\".format(i))\n",
    "    #plt.plot(np.linspace(0,10,100),np.linspace(0,10,100),'r-')\n",
    "    #print(radius/np.sqrt(2),found_radius,std_radius)\n",
    "    # plt.ylim((0,4))\n",
    "    # plt.xlim((0,4))\n",
    "plt.ylabel(\"Percent Error\")\n",
    "plt.xlabel(\"Simulated Radius (nm)\")\n",
    "plt.axvspan(min_rp_rad, max_rp_rad, alpha=0.2, color='red',label = \"rp_ez_spread\")\n",
    "plt.axvspan(min_ll_rad, max_ll_rad, alpha=0.2, color='green',label = \"ll_ez_spread\")\n",
    "#do the same for the hupa \n",
    "\n",
    "plt.ylim((-5,150))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_ez= run_analysis(wd=\"/Users/baljyot/Documents/CODE/GitHub_t2/Baljyot_EXP_RPOC/DATA/new_days/20190527/rpoc_ez\",\n",
    "                    t_string=\"rpoc_ez\")\n",
    "                    \n",
    "rp_ez.read_parameters(minimum_percent_per_drop_in = 0.9, \n",
    "                    t_len_u = 100, \n",
    "                    t_len_l=10, \n",
    "                    minimum_tracks_per_drop = 3)\n",
    "\n",
    "rp_ez.get_blob_parameters(threshold=1e-4,\n",
    "                        overlap=0,\n",
    "                        detection_name='bp',\n",
    "                        min_sigma=1/np.sqrt(2),\n",
    "                        max_sigma=6/np.sqrt(2),\n",
    "                        num_sigma=500,median = False)\n",
    "\n",
    "rp_ez.get_fitting_parameters(kwargs={\"mask_size\":3,\n",
    "                                    \"plot_fit\":False,\n",
    "                                    \"fitting_image\":\"Original\",\n",
    "                                    \"radius_func\":identity,\n",
    "                                    \"residual_func\":residuals_gaus2d,\n",
    "                                    \"sigma_range\":2,\n",
    "                                    \"centroid_range\":0.5,\n",
    "                                    \"height_range\":2})\n",
    "rp_ez.run_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radius(dataset,plot=True,bins=5):\n",
    "    radius = []\n",
    "    for i,j in dataset.Movie.items():\n",
    "        for k,l in j.Cells.items():\n",
    "            for m,n in l.Drop_Collection.items():\n",
    "                radius.append(n[2])\n",
    "    radius = np.array(radius)\n",
    "    radius = radius[radius>0]\n",
    "    radius_rp_ez = np.array(radius)*globals[\"olympus_pixel_size\"]\n",
    "    rad = []\n",
    "    for i,j in dataset.Movie.items():\n",
    "        for k,l in j.Cells.items():\n",
    "            for m,n in l.All_Drop_Collection.items():\n",
    "                rad.append(n[2])\n",
    "    rad = np.array(rad)\n",
    "    rad = rad[rad>0]\n",
    "    rad = rad*globals[\"olympus_pixel_size\"]\n",
    "    if plot:\n",
    "        plt.hist(radius_rp_ez,alpha = 0.1,label = \"viable\",bins=bins)\n",
    "        plt.hist(rad,alpha = 0.1, label = \"All\",bins=bins)\n",
    "        plt.xlabel(\"Radius in um\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return [radius_rp_ez,rad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "viable_rp,all_rp = get_radius(rp_ez,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _avg_points_drop(dataset):\n",
    "    drop_locs = {}\n",
    "    total_locs = {}\n",
    "    for i,j in dataset.Movie.items():\n",
    "        for k,l in j.Cells.items():\n",
    "            sorted_tracks = rp_ez._convert_track_frame(np.array(l.raw_tracks),t_len_l=1,t_len_u = 100)\n",
    "            for m,n in l.Drop_Collection.items():\n",
    "                counter = 0\n",
    "                total_localizations = 0\n",
    "                x,y = sorted_tracks[1],sorted_tracks[2]\n",
    "                for tt in range(len(x[int(m[0])])):\n",
    "                    for ttt in range(len(x[int(m[0])][tt])):\n",
    "                        total_localizations+=1\n",
    "                        if point_inside_circle2D(n,[x[int(m[0])][tt][ttt],y[int(m[0])][tt][ttt]]):\n",
    "                            counter+=1\n",
    "                drop_locs[\"{0},{1},{2}\".format(i,k,m)] = counter\n",
    "                total_locs[\"{0},{1},{2}\".format(i,k,m)] = total_localizations\n",
    "    return drop_locs,total_locs\n",
    "\n",
    "drop_localizations,total_localizations = _avg_points_drop(rp_ez)\n",
    "print(drop_localizations)\n",
    "avg_drop_localizations = np.mean(list(drop_localizations.values()))\n",
    "std_drop_localizations = np.std(list(drop_localizations.values()))\n",
    "print(avg_drop_localizations,std_drop_localizations,np.mean(list(total_localizations.values())),np.std(list(total_localizations.values())))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID = '1'\n",
    "a = rp_ez.Movie[movie_ID].Movie_nucleoid\n",
    "b = blob_detection(path = a,\\\n",
    "                    threshold=5e-3,\n",
    "                    overlap=1,\n",
    "                    min_sigma=1/np.sqrt(2),\n",
    "                    max_sigma=2.5/np.sqrt(2),\n",
    "                    num_sigma=500,\n",
    "                    median = False,\n",
    "                    verbose=True)\n",
    "b._update_fitting_parameters(kwargs={\"mask_size\":3,\n",
    "                                    \"plot_fit\":False,\n",
    "                                    \"fitting_image\":\"Original\",\n",
    "                                    \"radius_func\":identity,\n",
    "                                    \"residual_func\":residuals_gaus2d,\n",
    "                                    \"sigma_range\":10,\n",
    "                                    \"centroid_range\":0.5,\n",
    "                                    \"height_range\":2})\n",
    "c = b.detection(type='skimage')\n",
    "aa = read_file(a)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(aa,cmap = 'Greys')\n",
    "# for i in rp_ez.Movie['1'].Cells['1'].All_Drop_Collection.values():\n",
    "#     cir = plt.Circle((i[0],i[1]),radius=i[2], fill = False)\n",
    "#     ax.add_artist(cir)\n",
    "for i in c:\n",
    "    cir = plt.Circle((i[1],i[0]),radius=i[2]/2, fill = False)\n",
    "    ax.add_artist(cir)\n",
    "plt.show()\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rp_ez.Movie[movie_ID].Movie_nucleoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import filters\n",
    "%matplotlib widget\n",
    "#fig,ax = run_analysis_plotting.plot_img(rp_ez,1,movie_ID,1,int(\"0,2\"[0]))\n",
    "a =rp_ez._get_movie_path('1',0)\n",
    "b = blob_detection(path = a,\\\n",
    "                    median= True,\\\n",
    "                    threshold= 1e-4, \\\n",
    "                    min_sigma= 1, \\\n",
    "                    max_sigma = 3.5, \\\n",
    "                    num_sigma= 500, \\\n",
    "                    overlap = 0.8)\n",
    "c = b.detection(type = 'bp')\n",
    "aa = read_file(a)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "#ax.imshow(filters.median_filter(aa,size =1),cmap = 'Greys')\n",
    "ax.imshow(aa,cmap = 'Greys')\n",
    "for i in rp_ez.Movie['1'].Cells['1'].All_Drop_Collection.values():\n",
    "    cir = plt.Circle((i[0],i[1]),radius=i[2], fill = False)\n",
    "    ax.add_artist(cir)\n",
    "plt.show()\n",
    "print(rp_ez.Movie['1'].Cells['1'].All_Drop_Collection)\n",
    "print(rp_ez.Movie['1'].Cells['1'].All_Drop_Verbose)\n",
    "print(report_fit(rp_ez.Movie['1'].Cells['1'].All_Drop_Verbose['0,2'][\"Fit\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [5,7,10,15,20,30]\n",
    "axis_x = 2\n",
    "axis_y = 3\n",
    "x,y,fig,ax=run_analysis_plotting.draw_item(rp_ez,(axis_x,axis_y),all_tracks=False,cell_ID = '7',movie_ID='1')\n",
    "x_y = np.array([[a,b] for a,b in zip(x,y)])\n",
    "for i in range(axis_x):\n",
    "    for j in range(axis_y):\n",
    "        clustering = OPTICS(min_samples=samples[i*axis_x + j]).fit(x_y)\n",
    "        a = ax[i,j].scatter(x,y,s= 1,c = clustering.labels_)\n",
    "fig.colorbar(a)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in samples:\n",
    "    clustering = OPTICS(min_samples=i).fit(x_y)\n",
    "    a = plt.scatter(x,y,s= 1,c = clustering.labels_)\n",
    "    plt.colorbar(a)\n",
    "    plt.title(\"min_samples = {0}\".format(i))\n",
    "    plt.tight_layout()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = simulate_foci.sim_foci(max_x = 200,\n",
    "                            min_x = 0,\n",
    "                            radius = 50,\n",
    "                            center = [100,100],\n",
    "                            total_points = 500,\n",
    "                            density_dif = 5.0,\n",
    "                            pdf = simulate_foci.tophat_function_2d)\n",
    "sim_xy = sim._makePoints()\n",
    "for i in samples:\n",
    "    clustering = OPTICS(min_samples=i).fit(sim_xy)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    a = ax.scatter(sim_xy[:,0],sim_xy[:,1],s= 2,c = clustering.labels_)\n",
    "    plt.colorbar(a)\n",
    "    cir = plt.Circle(sim.center,radius = sim.radius,fill = False)\n",
    "    ax.set_title(\"min_samples = {0}\".format(i))\n",
    "    ax.add_artist(cir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt \n",
    "#train data on the best of above: samples = 30\n",
    "clustering_fit = DBSCAN(min_samples=30,eps = 1.0).fit(sim_xy)\n",
    "print(rp_ez.Movie['1'].Cells['1'].Drop_Collection)\n",
    "print(rp_ez.Movie['1'].Cells['4'].Drop_Collection)\n",
    "x,y,fig,ax=run_analysis_plotting.draw_item(rp_ez,cell_ID = ['1'],movie_ID='1',movie_frame_index = 0,all_tracks = 1)\n",
    "x_y = np.array([[a,b] for a,b in zip(x,y)])\n",
    "clustering = clustering_fit.fit_predict(x_y)\n",
    "a = ax.scatter(x,y,s= 1,c = clustering)\n",
    "fig.colorbar(a)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(len(x))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "a = ax.scatter(x,y,s= 20,c = clustering,cmap = \"Greys\")\n",
    "fig.colorbar(a)\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_fit = DBSCAN(min_samples=30,eps = 1.0).fit(sim_xy)\n",
    "x,y,fig,ax=run_analysis_plotting.draw_item(rp_ez,cell_ID = ['1'],movie_ID='1',movie_frame_index = 0,all_tracks = 1)\n",
    "x_y = np.array([[a,b] for a,b in zip(x,y)])\n",
    "clustering = clustering_fit.fit_predict(x_y)\n",
    "a = ax.scatter(x,y,s= 1,c = clustering)\n",
    "fig.colorbar(a)\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "non_cluster = np.where((np.asarray(clustering) >= 0))[0]\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "# a = read_file(rp_ez.Movie['1'].Movie_nucleoid)\n",
    "# ax.imshow(a,cmap = 'Greys')\n",
    "# a = ax.scatter(np.asarray(x)[non_cluster],np.asarray(y)[non_cluster],s= 20,c = clustering[non_cluster],cmap = \"Greys\")\n",
    "# fig.colorbar(a)\n",
    "# ax.set_xlim((120,190))\n",
    "# ax.set_ylim((55,100))\n",
    "# plt.gca().invert_yaxis()\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "a = read_file(rp_ez.Movie['1'].Movie_nucleoid)\n",
    "ax.imshow(a,cmap = 'Greys')\n",
    "a = ax.scatter(np.asarray(x)[non_cluster],np.asarray(y)[non_cluster],s= 20,c = clustering[non_cluster],cmap = \"Greys\")\n",
    "fig.colorbar(a)\n",
    "ax.set_xlim((170,240))\n",
    "ax.set_ylim((140,200))\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "a = read_file(rp_ez.Movie['1'].Movie_nucleoid)\n",
    "ax.imshow(a,cmap = 'Greys')\n",
    "#a = ax.scatter(np.asarray(x)[non_cluster],np.asarray(y)[non_cluster],s= 20,c = clustering[non_cluster],cmap = \"Greys\")\n",
    "#fig.colorbar(a)\n",
    "ax.set_xlim((170,240))\n",
    "ax.set_ylim((140,200))\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only take points in cluster one at a time\n",
    "unique_clusters = np.unique(clustering)[np.unique(clustering) > -1]\n",
    "cluster_xy = []\n",
    "for i in range(len(unique_clusters)):\n",
    "    indx_i = clustering == unique_clusters[i]\n",
    "    indx_i = np.array(indx_i)\n",
    "    x_indx = np.array(x)[indx_i]\n",
    "    y_indx = np.array(y)[indx_i]\n",
    "    #make pair \n",
    "    x_y_indx = np.array([[a,b] for a,b in zip(x_indx,y_indx)])\n",
    "    cluster_xy.append(x_y_indx)\n",
    "\n",
    "cluster_circles = []\n",
    "for i in cluster_xy:\n",
    "    circle = smallestenclosingcircle.make_circle(i)\n",
    "    cluster_circles.append(circle)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "a = ax.scatter(x,y,s= 20,c = clustering,cmap = \"Reds\")\n",
    "\n",
    "for i in cluster_circles:\n",
    "    Drawing_uncolored_circle = create_circle_obj(i,fill = False)\n",
    "    ax.add_artist(Drawing_uncolored_circle)\n",
    "\n",
    "\n",
    "fig.colorbar(a)\n",
    "plt.gca().invert_yaxis()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(cluster_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "\n",
    "which_object = rp_ez\n",
    "movie_ID = '0'\n",
    "cell_ID = '3'\n",
    "drop_ID = '0,0'\n",
    "copies = 1\n",
    "print(rp_ez.Movie[movie_ID].Cells[cell_ID].Drop_Collection)\n",
    "drop = which_object.Movie[movie_ID].Cells[cell_ID].Drop_Collection[drop_ID]\n",
    "cir = create_circle_obj(drop)\n",
    "fig,ax = run_analysis_plotting.plot_img(rp_ez,copies,movie_ID,cell_ID,int(drop_ID[0]))\n",
    "\n",
    "x_y = []\n",
    "\n",
    "def plot_lines(dic,color,fig,a,color_first = None,color_last = None):\n",
    "    len_tracks = []\n",
    "    for i,j in dic.items():\n",
    "        ax.plot(j.X,j.Y,color = color)\n",
    "        len_tracks.append(len(j.X))\n",
    "        if color_first != None:\n",
    "            ax.plot(j.X[0],j.Y[0],color = color_first,markersize = 2,marker = 'o')\n",
    "        if color_last != None:\n",
    "            ax.plot(j.X[-1],j.Y[-1],color = color_last,markersize = 2,marker = 'o')\n",
    "    return [len_tracks,fig,ax]\n",
    "    \n",
    "def plot_lines_bulk(movie_ID, cell_ID, drop_ID, fig, ax, plot_lines,**kwargs):\n",
    "    if kwargs.get(\"IN\",False) == True:\n",
    "        len_intracks = plot_lines(rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].IN_Trajectory_Collection,\n",
    "                            'red',fig,ax,color_first='black',color_last='grey')[0]\n",
    "    else:\n",
    "        len_intracks = None\n",
    "    if kwargs.get(\"Io\",False) == True:\n",
    "        len_iotracks = plot_lines(rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].IO_Trajectory_Collection,\n",
    "                            'orange',fig,ax,color_first='black',color_last='grey')[0]\n",
    "    else:\n",
    "        len_iotracks = None\n",
    "    if kwargs.get(\"OT\",False) == True:\n",
    "        len_ottracks = plot_lines(rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].OUT_Trajectory_Collection,\n",
    "                            'green',fig,ax,color_first='black',color_last='grey')[0]\n",
    "    else:\n",
    "        len_ottracks = None                            \n",
    "    return len_intracks,len_iotracks,len_ottracks\n",
    "\n",
    "len_intracks, len_iotracks, len_ottracks = plot_lines_bulk(movie_ID, cell_ID, drop_ID, fig, ax, plot_lines, IN = False, IO = False, OT = False)\n",
    "\n",
    "#use bounding box of the cell to define the limits of viewing\n",
    "bounding_box = which_object.Movie[movie_ID].Cells[cell_ID].bounding_box\n",
    "extended_view = 20\n",
    "ax.set_xlim((np.min(np.asarray(bounding_box[:,0]))-extended_view,np.max(np.asarray(bounding_box[:,0]))+extended_view))\n",
    "ax.set_ylim((np.min(np.asarray(bounding_box[:,1]))-extended_view,np.max(np.asarray(bounding_box[:,1]))+extended_view))\n",
    "ax.add_artist(cir)\n",
    "for i,j in which_object.Movie[movie_ID].Cells[cell_ID].All_Drop_Collection.items():\n",
    "    print(j)\n",
    "    cir = create_circle_obj(j)\n",
    "    ax.add_artist(cir)\n",
    "ax.set_title(\"Track Info: IN = {0}, IO = {1}, OT = {2}\".format(len_intracks,len_iotracks,len_ottracks))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "print(which_object.Movie[movie_ID].Cells[cell_ID].cell_area, which_object.Movie[movie_ID].Cells[cell_ID].cell_axis_lengths)\n",
    "print(bounding_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "\n",
    "which_object = rp_ez\n",
    "movie_ID = '1'\n",
    "cell_ID = '0'\n",
    "drop_ID = '0,1'\n",
    "copies = 1\n",
    "print(rp_ez.Movie[movie_ID].Cells[cell_ID].Drop_Collection)\n",
    "drop = which_object.Movie[movie_ID].Cells[cell_ID].Drop_Collection[drop_ID]\n",
    "cir = create_circle_obj(drop)\n",
    "fig,ax = run_analysis_plotting.plot_img(rp_ez,copies,movie_ID,cell_ID,int(drop_ID[0]))\n",
    "\n",
    "x_y = []\n",
    "\n",
    "def plot_lines(dic,color,fig,a,color_first = None,color_last = None):\n",
    "    len_tracks = []\n",
    "    for i,j in dic.items():\n",
    "        ax.plot(j.X,j.Y,color = color)\n",
    "        len_tracks.append(len(j.X))\n",
    "        if color_first != None:\n",
    "            ax.plot(j.X[0],j.Y[0],color = color_first,markersize = 2,marker = 'o')\n",
    "        if color_last != None:\n",
    "            ax.plot(j.X[-1],j.Y[-1],color = color_last,markersize = 2,marker = 'o')\n",
    "    return [len_tracks,fig,ax]\n",
    "\n",
    "len_intracks, len_iotracks, len_ottracks = plot_lines_bulk(movie_ID, cell_ID, drop_ID, fig, ax, plot_lines, IN = True, IO = False, OT = False)\n",
    "\n",
    "#use bounding box of the cell to define the limits of viewing\n",
    "bounding_box = which_object.Movie[movie_ID].Cells[cell_ID].bounding_box\n",
    "extended_view = 10\n",
    "ax.set_xlim((np.min(np.asarray(bounding_box[:,0]))-extended_view,np.max(np.asarray(bounding_box[:,0]))+extended_view))\n",
    "ax.set_ylim((np.min(np.asarray(bounding_box[:,1]))-extended_view,np.max(np.asarray(bounding_box[:,1]))+extended_view))\n",
    "ax.add_artist(cir)\n",
    "ax.set_title(\"Track Info: IN = {0}, IO = {1}, OT = {2}\".format(len_intracks,len_iotracks,len_ottracks))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "print(which_object.Movie[movie_ID].Cells[cell_ID].cell_area, which_object.Movie[movie_ID].Cells[cell_ID].cell_axis_lengths)\n",
    "print(bounding_box)\n",
    "\n",
    "def get_track_Tmsd(movie_ID, cell_ID, drop_ID):\n",
    "    for i,j in rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].IN_Trajectory_Collection.items():\n",
    "        print(\"IN: \", j.MSD_total_um, \" Distance from out \", j.distance_from_drop)\n",
    "    for i,j in rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].IO_Trajectory_Collection.items():\n",
    "        print(\"IO: \", j.MSD_total_um, \" Distance from out \", j.distance_from_drop)\n",
    "    for i,j in rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection[drop_ID].OUT_Trajectory_Collection.items():\n",
    "        print(\"OT: \", j.MSD_total_um, \" Distance from out \", j.distance_from_drop)\n",
    "\n",
    "get_track_Tmsd(movie_ID, cell_ID, drop_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "viable_rp,all_rp = get_radius(rp_ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "rp_ez_ba = boundary_analysis(dataset = rp_ez.Movie)\n",
    "rp_ez_aa = rp_ez_ba.directional_displacement_bulk(IN = True,IO = True, OT = True)\n",
    "a = rp_ez_ba.plot_directional_displacements(dir_displacements = rp_ez_aa[0],dist_center = rp_ez_aa[1],angles = rp_ez_aa[2])\n",
    "def adjust_axis(a,lim = 1.5):\n",
    "    a[2].set_xlim((-lim,lim))\n",
    "    a[2].set_ylim((-lim,lim))\n",
    "    a[2].set_aspect(1, adjustable='box')\n",
    "    plt.show()\n",
    "adjust_axis(a,lim = 3)\n",
    "\n",
    "def plot_pairCorrelation(aa,**kwargs):\n",
    "    x,y = rt_to_xy(np.array(aa[1]),aa[2])\n",
    "    g_r, radii, interior_points = centered_pairCorrelation_2D(x = x,\n",
    "                                                        y = y,\n",
    "                                                        center = kwargs.get('center',[0,0]),\n",
    "                                                        rMax = kwargs.get('rMax',1.1),\n",
    "                                                        dr = kwargs.get('dr',0.1))\n",
    "    if kwargs.get(\"fig\", None) == None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot()\n",
    "        ax.plot(radii,g_r)\n",
    "    else:\n",
    "        kwargs.get(\"ax\").plot(radii,g_r)\n",
    "    return [g_r, radii, interior_points,fig,ax]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = []\n",
    "centers = []\n",
    "disps = []\n",
    "for i,j in rp_ez.Movie.items():\n",
    "    for k,l in j.Cells.items():\n",
    "        sorted_tracks = rp_ez._convert_track_frame(track_set=np.array(l.raw_tracks),t_len_l = 1)\n",
    "        drops = l._convert_viableDrop_list()\n",
    "        for sf in range(len(sorted_tracks[0])):\n",
    "            x = sorted_tracks[1][sf]\n",
    "            y = sorted_tracks[2][sf]\n",
    "            drop = drops[sf]\n",
    "            if len(drop) > 0:\n",
    "                angle,center,disp = boundary_analysis._directional_variableTracks(x,y,drop)\n",
    "                angles+=angle\n",
    "                centers+=center\n",
    "                disps+=disp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(*rt_to_xy(np.array(rp_ez_aa[1]),rp_ez_aa[2]),s = 0.1)\n",
    "cir = plt.Circle((0,0),1,fill = False)\n",
    "ax.add_artist(cir)\n",
    "plt.xlim((-3,3))\n",
    "plt.ylim((-3,3))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(*rt_to_xy(np.array(centers),angles),s = 0.1)\n",
    "cir = plt.Circle((0,0),1,fill = False)\n",
    "ax.add_artist(cir)\n",
    "plt.xlim((-3,3))\n",
    "plt.ylim((-3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate drops of different radius \n",
    "def sim_drop(radius = 1,center = [100,100],**kwargs):\n",
    "    sim = simulate_foci.sim_foci(max_x = kwargs.get(\"max_x\",400),\n",
    "                            min_x = 0,\n",
    "                            radius = radius,\n",
    "                            center = center,\n",
    "                            total_points = kwargs.get(\"points\",1000),\n",
    "                            density_dif = kwargs.get(\"density\",50.0),\n",
    "                            pdf = simulate_foci.tophat_function_2d)\n",
    "    sim_xy = sim._makePoints()\n",
    "    return sim_xy\n",
    "radi = np.arange(10,50,3)\n",
    "centers = np.random.randint(50,150,size = (2,len(radi)))\n",
    "\n",
    "mapped = []\n",
    "for i in range(len(radi)):\n",
    "    xy = sim_drop(radius=radi[i],center=centers[:,i])\n",
    "    mapped.append([xy[:,0],xy[:,1],[centers[:,i][0],centers[:,i][1],radi[i]]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "angle,center,disp = boundary_analysis._directional_displacement_utility(mapped)\n",
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(*rt_to_xy(np.array(center),angle),s = 0.1)\n",
    "cir = plt.Circle((0,0),1,fill = False)\n",
    "ax.add_artist(cir)\n",
    "plt.xlim((-3,3))\n",
    "plt.ylim((-3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mapped)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    a = ax.scatter(mapped[i][0],mapped[i][1],s= 2)\n",
    "    cir = plt.Circle((mapped[i][2][0],mapped[i][2][1]),mapped[i][2][2],fill = False)\n",
    "    ax.add_artist(cir)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID = '1'\n",
    "cell_ID = '1'\n",
    "frame = 0\n",
    "\n",
    "seg_frame = rp_ez._get_movie_path(movie_ID=movie_ID,frame=frame)\n",
    "gfp_img = rp_ez._get_nucleoid_path(movie_ID=movie_ID,cell_ID=cell_ID,full_path=False)\n",
    "shape = np.shape(gfp_img)\n",
    "x,y = np.meshgrid(np.arange(0,shape[0],1),np.arange(0,shape[1],1),indexing = 'ij')\n",
    "\n",
    "print(rp_ez.Movie[movie_ID].Cells[cell_ID].bounding_box)\n",
    "print(rp_ez.Movie[movie_ID].Cells[cell_ID].r_offset)\n",
    "print(rp_ez.Movie[movie_ID].Cells[cell_ID].Drop_Collection)\n",
    "\n",
    "\n",
    "def rescale_range(x,min_x,max_x,a,b):\n",
    "    '''https://stats.stackexchange.com/questions/281162/scale-a-number-between-a-range'''\n",
    "    return ((b-a)*(x - min_x)/(max_x - min_x)) + a\n",
    "\n",
    "def _gaussian_mesh_helper(mesh_2d,initial_xy,sub_arr = [3,3]):\n",
    "    ''' \n",
    "    takes a 2d_mesh (image data) and a bounding box to return a list of (x,y,z) in that bounding box\n",
    "    box is implimented from the center point of the pixel.\n",
    "    '''\n",
    "    #make x,y,z list from mesh data\n",
    "    #find dims\n",
    "    sub_arr = np.array(sub_arr)\n",
    "    initial_xy = np.array(initial_xy)\n",
    "    minx,miny = initial_xy - sub_arr\n",
    "    maxx,maxy = initial_xy + sub_arr\n",
    "    minx,miny = int(minx),int(miny)\n",
    "    maxx,maxy =int(maxx),int(maxy)\n",
    "    centers = [rescale_range(initial_xy[0],minx,maxx,0,-2*sub_arr[1]+1),rescale_range(initial_xy[1],miny,maxy,0,-2*sub_arr[0]+1)]\n",
    "    x,y = np.meshgrid(np.arange(minx,maxx,1),np.arange(miny,maxy,1))\n",
    "    mesh_view = mesh_2d[minx:maxx,miny:maxy]\n",
    "    \n",
    "    return [x-maxx+1,y-maxy+1,mesh_view,centers]\n",
    "\n",
    "xk,yk,zk,centers = _gaussian_mesh_helper(gfp_img,rp_ez.Movie[movie_ID].Cells[cell_ID].Drop_Collection['0,1'][:-1],sub_arr=[10,10])\n",
    "x_cent = centers[0]\n",
    "y_cent = centers[1]\n",
    "# plt.clf()\n",
    "# plt.imshow(zk)\n",
    "# plt.show()\n",
    "import lmfit\n",
    "from lmfit import Parameters, minimize, report_fit\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "\n",
    "def sim_foci_pdf(max_x,radius,center,density_dif,points,sigma):\n",
    "    min_x = 0\n",
    "    max_x = max_x\n",
    "    x1,y1 = tf.cast(tf.linspace(min_x,max_x,max_x),tf.float64), tf.cast(tf.linspace(min_x,max_x,max_x),tf.float64)\n",
    "    a = sim_drop(radius=radius,center=center,density_dif = density_dif,max_x = max_x, points = points)\n",
    "    x = a[:,0]\n",
    "    y = a[:,1]\n",
    "    sigma = np.array([sigma,sigma],dtype = type(a[0][0]))\n",
    "    z = 0\n",
    "    for i in range(len(a)):\n",
    "        z += np.array(simulate_foci.get_gaussian(a[i], sigma,domain = [x1,x1]))\n",
    "    return x1,y1,z\n",
    "\n",
    "x1, y1, z = sim_foci_pdf(max_x=200,radius=2.5,center=[100,100],density_dif=100.,points=1000,sigma=1)\n",
    "\n",
    "def gaussian2D(x, y, cen_x, cen_y, sig_x, sig_y, offset):\n",
    "    return np.exp(-(((cen_x-x)/sig_x)**2 + ((cen_y-y)/sig_y)**2)/2.0) + offset\n",
    "\n",
    "def gaus_constrained(x,y,sig_x,offset,kwargs = {}):\n",
    "    return gaussian2D(x, y, cen_x = kwargs.get(\"cen_x\",100), cen_y = kwargs.get(\"cen_y\",100), sig_x = sig_x, sig_y = kwargs.get(\"sig_y\",sig_x),offset = offset)\n",
    "\n",
    "\n",
    "def residuals(p, x, y, z,**kwargs):\n",
    "    height = p[\"height\"].value\n",
    "    #cen_x = p[\"centroid_x\"].value\n",
    "    #cen_y = p[\"centroid_y\"].value\n",
    "    sigma_x = p[\"sigma_x\"].value\n",
    "    #sigma_y = p[\"sigma_y\"].value\n",
    "    offset = p[\"background\"].value\n",
    "    return (z - height*gaus_constrained(x,y,sigma_x,offset,kwargs=kwargs))#gaussian2D(x,y, cen_x = cen_x, cen_y = cen_y, sig_x = sigma_x, sig_y = sigma_y, offset = offset))\n",
    "\n",
    "def initalize_2dgaus(**kwargs):\n",
    "    initial = Parameters()\n",
    "    for i,j in kwargs.items():\n",
    "        initial.add(i,value = j)\n",
    "    # initial.add(\"height\",value=.3)\n",
    "    # #initial.add(\"centroid_x\",value=100.)\n",
    "    # #initial.add(\"centroid_y\",value=100.)\n",
    "    # initial.add(\"sigma_x\",value=20.)\n",
    "    # #initial.add(\"sigma_y\",value=20.)\n",
    "    # initial.add(\"background\",value=0.015)\n",
    "    return initial\n",
    "\n",
    "initial = initalize_2dgaus(height = 0.3,sigma_x = 20.,background = 0.015)\n",
    "\n",
    "xx,yy = np.meshgrid(x1,y1,indexing=\"xy\")\n",
    "fit = minimize(residuals, initial, args=(yy, xx, z), kws = {\"cen_x\":100,\"cen_y\":100})\n",
    "print(report_fit(fit))\n",
    "#z1 = fit.params[\"height\"]*gaussian2D(xx,yy, cen_x = fit.params[\"centroid_x\"], cen_y = fit.params[\"centroid_y\"], sig_x = fit.params[\"sigma_x\"], sig_y = fit.params[\"sigma_y\"], offset = fit.params[\"background\"])\n",
    "z1 = fit.params[\"height\"]*gaus_constrained(xx,yy,fit.params[\"sigma_x\"],fit.params[\"background\"])\n",
    "# plt.clf() \n",
    "# #Change the Size of Graph using Figsize\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    " \n",
    "\n",
    "# #Generating a 3D sine wave\n",
    "# ax = plt.axes(projection='3d')\n",
    "\n",
    "# x,y = np.meshgrid(x1,y1)\n",
    "# ax.plot_wireframe(x,y,z)\n",
    "# ax.plot_wireframe(x,y,z1,color = \"green\")\n",
    "# #plt.imshow(gfp_img,cmap = \"Greys\")\n",
    "# plt.show()\n",
    "initial = initalize_2dgaus(height = 10000,sigma_x = 2.,background = 100)\n",
    "fit = minimize(residuals, initial, args=(yk, xk, zk), kws = {\"cen_x\":x_cent,\"cen_y\":y_cent})\n",
    "print(report_fit(fit))\n",
    "z1 = fit.params[\"height\"]*gaus_constrained(xk,yk,fit.params[\"sigma_x\"],fit.params[\"background\"],kwargs = {\"cen_x\":x_cent,\"cen_y\":y_cent})\n",
    "plt.clf() \n",
    "\n",
    "#Change the Size of Graph using Figsize\n",
    "fig = plt.figure(figsize=(10,10))\n",
    " \n",
    "\n",
    "#Generating a 3D sine wave\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_wireframe(xk,yk,zk)\n",
    "ax.scatter3D(x_cent,y_cent,10000)\n",
    "ax.plot_wireframe(xk,yk,z1,color = \"green\")\n",
    "#plt.imshow(gfp_img,cmap = \"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_ez.Movie['0'].Cells['0'].Trajectory_Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rp_ez_ba.directional_displacement(rp_ez.Movie['1'].Cells['0'].Trajectory_Collection['0,1'].IN_Trajectory_Collection,rp_ez.Movie['1'].Cells['0'])\n",
    "b = rp_ez_ba.plot_directional_displacements(dir_displacements = a[2],dist_center = a[1],angles = a[0])\n",
    "adjust_axis(b)\n",
    "print(len(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_ez= run_analysis(\"DATA/new_days/20190527/ll_ez\",\"laco_laci_ez\")\n",
    "ll_ez.read_parameters(minimum_percent_per_drop_in = 0.5, t_len_u = 50, t_len_l=10, minimum_tracks_per_drop = 3)\n",
    "ll_ez.get_blob_parameters(threshold = 1e-4,overlap=0.5,detection_name='bp',min_sigma=1./np.sqrt(2), \\\n",
    "                            max_sigma=3/np.sqrt(2),num_sigma=500,median = False)\n",
    "ll_ez.get_fitting_parameters(kwargs={\"mask_size\":3,\n",
    "                                    \"plot_fit\":False,\n",
    "                                    \"fitting_image\":\"Original\",\n",
    "                                    \"radius_func\":None,\n",
    "                                    \"residual_func\":iso_gaus,\n",
    "                                    \"sigma_range\":0.5,\n",
    "                                    \"centroid_range\":0.5,\n",
    "                                    \"height_range\":2})\n",
    "ll_ez.run_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_localizations,total_localizations = _avg_points_drop(ll_ez)\n",
    "print(drop_localizations)\n",
    "avg_drop_localizations = np.mean(list(drop_localizations.values()))\n",
    "std_drop_localizations = np.std(list(drop_localizations.values()))\n",
    "print(avg_drop_localizations,std_drop_localizations,np.mean(list(total_localizations.values())),np.std(list(total_localizations.values())))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "viable_ll=get_radius(ll_ez,bins = 10)\n",
    "print(viable_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID = '5'\n",
    "a = ll_ez.Movie[movie_ID].Movie_nucleoid\n",
    "b = blob_detection(path = a,\\\n",
    "                    median= False,\\\n",
    "                    threshold= 0.015, \\\n",
    "                    min_sigma= 1, \\\n",
    "                    max_sigma = 2, \\\n",
    "                    num_sigma= 200, \\\n",
    "                    overlap = 0)\n",
    "c = b.detection()\n",
    "aa = read_file(a)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(aa,cmap = 'Greys')\n",
    "for i in c:\n",
    "    cir = plt.Circle((i[1],i[0]),radius=i[2], fill = False)\n",
    "    ax.add_artist(cir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ll_ez_ba = boundary_analysis(dataset = ll_ez.Movie)\n",
    "ll_ez_aa = ll_ez_ba.directional_displacement_bulk(IN = True,IO = True, OT = True)\n",
    "b = ll_ez_ba.plot_directional_displacements(dir_displacements = ll_ez_aa[0],dist_center = ll_ez_aa[1],angles = ll_ez_aa[2])\n",
    "\n",
    "adjust_axis(b)\n",
    "\n",
    "# radius = []\n",
    "# for i,j in ll_ez.Movie.items():\n",
    "#     for k,l in j.Cells.items():\n",
    "#         for m,n in l.Drop_Collection.items():\n",
    "#             radius.append(n[2])\n",
    "# radius_ll_ez = np.array(radius)*0.13\n",
    "# plt.hist(radius_ll_ez,alpha = 0.1,label = \"viable\")\n",
    "# plt.hist(np.array(ll_ez.radius)[:,2]*0.13,alpha = 0.1, label = \"All\")\n",
    "# plt.xlabel(\"Radius in um\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.hist(radius_ll_ez,alpha = 0.1,label = \"ll\")\n",
    "# plt.hist(radius_rp_ez,alpha = 0.1,label = \"rp\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# plt.plot(ll_ez_aa[0],ll_ez_aa[2],'b.')\n",
    "# plt.show()\n",
    "print(np.sum(np.asarray(rp_ez_aa[1])>5))\n",
    "a = plot_pairCorrelation(ll_ez_aa, dr = 0.05, rMax = 1.)\n",
    "b = plot_pairCorrelation(rp_ez_aa, ax = a[4], dr = 0.05, rMax = 1.)\n",
    "plt.show()\n",
    "plt.plot(a[1],a[0],label = \"ll_ez\")\n",
    "plt.plot(b[1],b[0],label = \"rp_ez\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"radius\")\n",
    "plt.ylabel(\"g(r)\")\n",
    "plt.hlines(y = 1, xmin = 0, xmax = 1.5)\n",
    "\n",
    "\n",
    "rMax = 1\n",
    "dr = 0.05\n",
    "edges = np.arange(0,rMax,dr)\n",
    "resl,binsl = np.histogram(ll_ez_aa[1],bins = edges)\n",
    "resr,binsr = np.histogram(rp_ez_aa[1],bins = edges)\n",
    "num_radiusl = len(np.where(np.asarray(ll_ez_aa[1]) <= rMax)[0])\n",
    "num_radiusr = len(np.where(np.asarray(rp_ez_aa[1]) <= rMax)[0])\n",
    "space_density = np.zeros(len(edges)-1)\n",
    "radius = np.zeros(len(edges)-1)\n",
    "for i in range(len(edges)-1):\n",
    "    space_density[i] = np.pi*(edges[i+1]**2 - edges[i]**2)\n",
    "    radius[i] = (edges[i+1] - edges[i])/2\n",
    "# plt.clf()\n",
    "# plt.plot(binsl[:-1],resl)\n",
    "# plt.plot(binsr[:-1],resr)\n",
    "# plt.show()\n",
    "# plt.plot(radius,((resl/num_radiusl)/(np.pi*rMax*rMax)) / space_density)\n",
    "# plt.plot(radius,((resr/num_radiusr)/(np.pi*rMax*rMax)) / space_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = ll_ez\n",
    "y_collection = []\n",
    "x_collection = []\n",
    "in_msd = []\n",
    "io_msd = []\n",
    "radius_col = []\n",
    "\n",
    "#cm of track to boundary vs diff\n",
    "cm_boundary = []\n",
    "cm_diff = []\n",
    "track_recidency_in_drop = []\n",
    "cm_error = []\n",
    "end_to_end = []\n",
    "radius_gyration = []\n",
    "\n",
    "IO_inside_start = []\n",
    "IO_inside_start_dist = []\n",
    "IO_outside_start = []\n",
    "IO_outside_start_dist = []\n",
    "#number of tracks that start inside and end inside\n",
    "tracks_in_in = 0\n",
    "len_ii = []\n",
    "tracks_out_out = 0\n",
    "len_oo = []\n",
    "tracks_in_out = 0\n",
    "len_io = []\n",
    "tracks_out_in = 0\n",
    "len_oi = []\n",
    "directional_displacement = []\n",
    "dist_center = []\n",
    "long_axis_angle = []\n",
    "\n",
    "#take notice of tracks which have displacements away from the condensate (in/out only) of >0.2 um\n",
    "track_xy = []\n",
    "track_drop = []\n",
    "track_movie = []\n",
    "track_cell = []\n",
    "track_cell_e1_e2 = []\n",
    "displacement_aligned_long = []\n",
    "track_drop_loc = []\n",
    "track_id = []\n",
    "angles = []\n",
    "for k,v in which.Movie.items():\n",
    "   for o,oo in which.Movie[k].Cells.items():\n",
    "      for kk,vv in which.Movie[k].Cells[o].Trajectory_Collection.items():\n",
    "          \n",
    "          for kkk,vvv in which.Movie[k].Cells[o].Trajectory_Collection[kk].IN_Trajectory_Collection.items():\n",
    "              track = which.Movie[k].Cells[o].Trajectory_Collection[kk].IN_Trajectory_Collection[kkk]\n",
    "              x_val = track.X\n",
    "              y_val = track.Y\n",
    "              drop_data = which.Movie[k].Cells[o].Drop_Collection[track.Drop_Identifier]\n",
    "\n",
    "              diff_dist_temp = con_pix_si(dif_dis(x_val,y_val),which = 'um')\n",
    "              drop_center_dist = (dist(x_val,y_val,drop_data[0],drop_data[1]))-drop_data[2]\n",
    "              angles += list(angle_dist(x_val,y_val,drop_data[0],drop_data[1]))\n",
    "\n",
    "              #direction of the trajectory\n",
    "              #r2 -r1 > 0 moving out, r2 - r1 < 0 moving in\n",
    "              directional = con_pix_si(np.diff(dist(x_val,y_val,drop_data[0],drop_data[1])),which = 'um')\n",
    "              directional_displacement+=list(directional)\n",
    "              dist_center+=list(drop_center_dist)[:-1]\n",
    "\n",
    "              radius_col.append(drop_data[2])\n",
    "              y_collection+=list(diff_dist_temp)\n",
    "              x_collection+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "\n",
    "              in_msd.append(track.MSD_total_um)\n",
    "\n",
    "              #center of mass of track relative to boundary vs. diffusion of track\n",
    "              cm = cm_normal(x_val,y_val)\n",
    "              cm_dist_boundary = dist(cm[0],cm[1],drop_data[0],drop_data[1]) - drop_data[2]\n",
    "              cm_boundary.append(con_pix_si(cm_dist_boundary,which = 'um'))\n",
    "              cm_diff.append(track.MSD_total_um)\n",
    "              cm_error.append(np.sqrt(np.std(x_val)**2 + np.std(y_val)**2)/np.sqrt(len(x_val)))\n",
    "              track_recidency_in_drop.append(np.sum(drop_center_dist<0.0)/len(x_val))\n",
    "              #end ot end distance of trajectory:\n",
    "              end_to_end.append(end_distance(x_val,y_val))\n",
    "\n",
    "              #radius of gyration\n",
    "              radius_gyration.append(radius_of_gyration(x_val,y_val))\n",
    "\n",
    "\n",
    "\n",
    "              #how aligned is the displacement vector for each displacement to each axis of the cell. \n",
    "              #differences in x,y\n",
    "              dif_x = np.diff(x_val)\n",
    "              dif_y = np.diff(y_val)\n",
    "              long_axis_vec = which.Movie[k].Cells[o].cell_long_axis\n",
    "              angle_xy = []\n",
    "              for i in range(len(dif_x)):\n",
    "                  termer = np.arccos(np.dot(long_axis_vec.T[0],[dif_x[i],dif_y[i]])/(np.linalg.norm(long_axis_vec.T[0])*np.linalg.norm([dif_x[i],dif_y[i]])))*180/np.pi\n",
    "                  angle_xy.append(termer)\n",
    "              long_axis_angle+=angle_xy\n",
    "\n",
    "\n",
    "          for kkk,vvv in which.Movie[k].Cells[o].Trajectory_Collection[kk].IO_Trajectory_Collection.items():\n",
    "              track = which.Movie[k].Cells[o].Trajectory_Collection[kk].IO_Trajectory_Collection[kkk]\n",
    "              x_val = track.X\n",
    "              y_val = track.Y\n",
    "              drop_data = which.Movie[k].Cells[o].Drop_Collection[track.Drop_Identifier]\n",
    "                  \n",
    "              diff_dist_temp = con_pix_si(dif_dis(x_val,y_val),which = 'um')\n",
    "              drop_center_dist = (dist(x_val,y_val,drop_data[0],drop_data[1]) - drop_data[2])/drop_data[2]\n",
    "              angles += list(angle_dist(x_val,y_val,drop_data[0],drop_data[1])[:-1])\n",
    "              #direction of the trajectory\n",
    "              #r2 -r1 > 0 moving out, r2 - r1 < 0 moving in\n",
    "              directional = con_pix_si(np.diff(dist(x_val,y_val,drop_data[0],drop_data[1])),which = 'um')\n",
    "              directional_displacement+=list(directional)\n",
    "              dist_center+=list(drop_center_dist[:-1])\n",
    "\n",
    "              radius_col.append(drop_data[2])\n",
    "              y_collection+=list(diff_dist_temp)\n",
    "              x_collection+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "              io_msd.append(track.MSD_total_um)\n",
    "\n",
    "              #center of mass of track relative to boundary vs. diffusion of track\n",
    "              cm = cm_normal(x_val,y_val)\n",
    "              cm_dist_boundary = dist(cm[0],cm[1],drop_data[0],drop_data[1]) - drop_data[2]\n",
    "              cm_boundary.append(con_pix_si(cm_dist_boundary,which = 'um'))\n",
    "              cm_diff.append(track.MSD_total_um)\n",
    "              cm_error.append(np.sqrt(np.std(x_val)**2 + np.std(y_val)**2))\n",
    "              track_recidency_in_drop.append(np.sum(drop_center_dist<0.0)/len(x_val))\n",
    "              #end ot end distance of trajectory:\n",
    "              end_to_end.append(end_distance(x_val,y_val))\n",
    "\n",
    "              #radius of gyration\n",
    "              radius_gyration.append(radius_of_gyration(x_val,y_val))\n",
    "\n",
    "              #how aligned is the displacement vector for each displacement to each axis of the cell. \n",
    "              #differences in x,y\n",
    "              dif_x = np.diff(x_val)\n",
    "              dif_y = np.diff(y_val)\n",
    "              long_axis_vec = which.Movie[k].Cells[o].cell_long_axis\n",
    "              angle_xy = []\n",
    "              for i in range(len(dif_x)):\n",
    "                  termer = np.arccos(np.dot(long_axis_vec.T[0],[dif_x[i],dif_y[i]])/(np.linalg.norm(long_axis_vec.T[0])*np.linalg.norm([dif_x[i],dif_y[i]])))*180/np.pi\n",
    "                  angle_xy.append(termer)\n",
    "              long_axis_angle+=angle_xy\n",
    "              #check the tracks which have displacements way outside the condensate and ask how are they oriented relative to the cell axis and where the condensate is\n",
    "              if np.sum(np.array(con_pix_si(drop_center_dist[:-1], which = 'um'))>-0.4) != 0:\n",
    "                  track_xy.append([x_val,y_val])\n",
    "                  track_drop.append(which.Movie[k].Cells[o].Drop_Collection[track.Drop_Identifier])\n",
    "                  track_drop_loc.append(track.Drop_Identifier)\n",
    "                  track_id.append(kkk)\n",
    "                  track_movie.append(k)\n",
    "                  track_cell.append(o)\n",
    "                  track_cell_e1_e2.append([which.Movie[k].Cells[o].cell_long_axis,which.Movie[k].Cells[o].cell_short_axis])\n",
    "                  #how aligned is the displacement vector for each displacement to each axis of the cell. \n",
    "                  #differences in x,y\n",
    "                  dif_x = np.diff(x_val)\n",
    "                  dif_y = np.diff(y_val)\n",
    "                  long_axis_vec = which.Movie[k].Cells[o].cell_long_axis\n",
    "                  angle_xy = []\n",
    "                  for i in range(len(dif_x)):\n",
    "                      termer = np.arccos(np.dot(long_axis_vec.T[0],[dif_x[i],dif_y[i]])/(np.linalg.norm(long_axis_vec.T[0])*np.linalg.norm([dif_x[i],dif_y[i]])))*180/np.pi\n",
    "                      angle_xy.append(termer)\n",
    "\n",
    "\n",
    "\n",
    "              #for IO trajectories that start in the inside of condensates how do they behave?\n",
    "              distances_center = dist(x_val,y_val,drop_data[0],drop_data[1]) \n",
    "              index_radius = distances_center<drop_data[2]\n",
    "              # index_index = 0\n",
    "              # for i in range(len(index_radius)):\n",
    "              #     if i==0:\n",
    "              #         index_index = index_radius[i]\n",
    "              #     else:\n",
    "\n",
    "\n",
    "              if (index_radius[0] == True) and (index_radius[-1] == True):\n",
    "                  IO_inside_start+=list(diff_dist_temp)\n",
    "                  IO_inside_start_dist+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "                  tracks_in_in+=1\n",
    "                  len_ii.append(len(index_radius))\n",
    "              elif (index_radius[0] == False) and (index_radius[-1] == False):\n",
    "                  IO_outside_start+=list(diff_dist_temp)\n",
    "                  IO_outside_start_dist+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "                  tracks_out_out+=1\n",
    "                  len_oo.append(len(index_radius))\n",
    "              if (index_radius[0] == False) and (index_radius[-1] == True):\n",
    "                  tracks_out_in+=1\n",
    "                  len_oi.append(len(index_radius))\n",
    "              if (index_radius[0] == True) and (index_radius[-1] == False):\n",
    "                  tracks_in_out+=1\n",
    "                  len_io.append(len(index_radius))\n",
    "\n",
    "          # for kkk,vvv in which.Movie[k].Cells[o].Trajectory_Collection[kk].OUT_Trajectory_Collection.items():\n",
    "          #     track = which.Movie[k].Cells[o].Trajectory_Collection[kk].OUT_Trajectory_Collection[kkk]\n",
    "          #     x_val = track.X\n",
    "          #     y_val = track.Y\n",
    "          #     drop_data = which.Movie[k].Cells[o].Drop_Collection[track.Drop_Identifier]\n",
    "                  \n",
    "          #     diff_dist_temp = con_pix_si(dif_dis(x_val,y_val),which = 'um')\n",
    "          #     drop_center_dist = dist(x_val,y_val,drop_data[0],drop_data[1]) - drop_data[2]\n",
    "\n",
    "          #     #direction of the trajectory\n",
    "          #     #r2 -r1 > 0 moving out, r2 - r1 < 0 moving in\n",
    "          #     directional = con_pix_si(np.diff(dist(x_val,y_val,drop_data[0],drop_data[1])),which = 'um')\n",
    "          #     directional_displacement+=list(directional)\n",
    "          #     dist_center+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "\n",
    "          #     radius_col.append(drop_data[2])\n",
    "          #     y_collection+=list(diff_dist_temp)\n",
    "          #     x_collection+=list(con_pix_si(drop_center_dist[:-1], which = 'um'))\n",
    "          #     io_msd.append(track.MSD_total_um)\n",
    "\n",
    "          #     #center of mass of track relative to boundary vs. diffusion of track\n",
    "          #     cm = cm_normal(x_val,y_val)\n",
    "          #     cm_dist_boundary = dist(cm[0],cm[1],drop_data[0],drop_data[1]) - drop_data[2]\n",
    "          #     cm_boundary.append(con_pix_si(cm_dist_boundary,which = 'um'))\n",
    "          #     cm_diff.append(track.MSD_total_um)\n",
    "          #     cm_error.append(np.sqrt(np.std(x_val)**2 + np.std(y_val)**2))\n",
    "          #     track_recidency_in_drop.append(np.sum(drop_center_dist<0.0)/len(x_val))\n",
    "          #     #end ot end distance of trajectory:\n",
    "          #     end_to_end.append(end_distance(x_val,y_val))\n",
    "\n",
    "          #     #radius of gyration\n",
    "          #     radius_gyration.append(radius_of_gyration(x_val,y_val))\n",
    "\n",
    "\n",
    "#plotting tracks on cells\n",
    "\n",
    "\n",
    "#get the '2' movie:\n",
    "movie_selc = '7'\n",
    "\n",
    "ind_m = np.array(track_movie) == movie_selc\n",
    "cells_m = np.array(track_cell)[ind_m]\n",
    "drops_m = np.array(track_drop)[ind_m]\n",
    "tracks_m = np.array(track_xy)[ind_m]\n",
    "drop_loc_m = np.array(track_drop_loc)[ind_m]\n",
    "track_idm = np.array(track_id)[ind_m]\n",
    "\n",
    "\n",
    "\n",
    "cmap_all=plt.get_cmap('gray')\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(len(tracks_m)):\n",
    "    img = mpimg.imread(which.Movie[movie_selc].Movie_location[int(drop_loc_m[i][0])])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    pimg = ax.imshow(img,cmap=cmap_all)\n",
    "    ax.plot(tracks_m[i][0],tracks_m[i][1],'-') \n",
    "    cir = Circle([drops_m[i][0],drops_m[i][1]], radius =drops_m[i][2], fill = False, color = 'red')\n",
    "    ax.add_artist(cir)\n",
    "    for k,l in which.Movie[movie_selc].Cells[cells_m[i]].Drop_Collection.items():\n",
    "\n",
    "        print(drops_m[i])\n",
    "        if k[0] == track_idm[i][0]:\n",
    "            cir = Circle([l[0],l[1]], radius =l[2], fill = False, color = \"black\")\n",
    "            ax.add_artist(cir)\n",
    "    plt.xlim((50,120))\n",
    "    plt.ylim((180,240))\n",
    "    plt.show()\n",
    "'''\n",
    "for i in range(len(tracks_m)):\n",
    "    if i == 0:\n",
    "      img = mpimg.imread(which.Movie[movie_selc].Movie_location[int(drop_loc_m[i][0])])\n",
    "      fig = plt.figure()\n",
    "      ax = plt.axes(projection='3d')\n",
    "      nx,ny = np.shape(img)\n",
    "      x = range(nx)\n",
    "      y = range(ny)\n",
    "      X, Y = np.meshgrid(x, y)\n",
    "      ax.plot_surface(X[50:120,190:240], Y[50:120,190:240], img[190:240,50:120].T, rstride=1, cstride=1,cmap='viridis', edgecolor='none')\n",
    "      cir = Circle([drops_m[i][1],drops_m[i][0]], radius =drops_m[i][2], fill = False, color = 'red')\n",
    "      ax.add_patch(cir)\n",
    "      art3d.pathpatch_2d_to_3d(cir, z=200)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#directional_displacement\n",
    "x = np.array(dist_center)\n",
    "y = np.array(directional_displacement)\n",
    "xy = np.vstack([dist_center,directional_displacement])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "# angles = np.array(angles)\n",
    "\n",
    "# def rt_to_xy(r,theta):\n",
    "#     y = r*np.sin(theta)\n",
    "#     x = r*np.cos(theta)\n",
    "#     return np.array([x,y])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "# ax.scatter(*rt_to_xy(x,angles),c = long_axis_angle,s = 0.1)\n",
    "# cir = plt.Circle( (0,0) ,1,fill = False )\n",
    "# ax.plot(0,0,'bo',markersize = 2)\n",
    "# plt.colorbar()\n",
    "# ax.add_artist(cir)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import binned_statistic_2d\n",
    "a,b,c,d = binned_statistic_2d(x,y,None,'count',bins = 50, expand_binnumbers = True)\n",
    "\n",
    "weights2 = np.ones_like(y[(d[0]==5) | (d[0]==6) | (d[0]==7) | (d[0]==8)]) / (len(y[(d[0]==5) | (d[0]==6) | (d[0]==7) | (d[0]==8)]))\n",
    "weights1 = np.ones_like(y[(d[0]==9) | (d[0]==10) | (d[0]==11) | (d[0]==12)]) / (len(y[(d[0]==9) | (d[0]==10) | (d[0]==11) | (d[0]==12)]))\n",
    "plt.hist(y[(d[0]==9) | (d[0]==10) | (d[0]==11) | (d[0]==12)],alpha = 0.3,label = \"Boundary\",weights=weights1)\n",
    "plt.hist(y[(d[0]==5) | (d[0]==6) | (d[0]==7) | (d[0]==8)],alpha = 0.3,label = \"Droplet Phase\",weights=weights2)\n",
    "plt.xlabel(\"Directional Displacements (um)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist(abs(y[(d[0]==9) | (d[0]==10) | (d[0]==11) | (d[0]==12)]),alpha = 0.3,label = \"Boundary\",weights=weights1)\n",
    "plt.hist(abs(y[(d[0]==5) | (d[0]==6) | (d[0]==7) | (d[0]==8)]),alpha = 0.3,label = \"Droplet Phase\",weights=weights2)\n",
    "plt.show()\n",
    "\n",
    "weights1 = np.ones_like(y[(d[0]==2) | (d[0]==3) | (d[0]==4)]) / (len(y[(d[0]==2) | (d[0]==3) | (d[0]==4)]))\n",
    "weights2 = np.ones_like(y[(d[0]==5) | (d[0]==6) | (d[0]==7)]) / (len(y[(d[0]==5) | (d[0]==6) | (d[0]==7)]))\n",
    "plt.hist(y[(d[0]==2) | (d[0]==3) | (d[0]==4)],alpha = 0.3,label = \"Boundary\",weights=weights1)\n",
    "plt.hist(y[(d[0]==5) | (d[0]==6) | (d[0]==7)],alpha = 0.3,label = \"Droplet Phase\",weights=weights2)\n",
    "plt.xlabel(\"Directional Displacements (um)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.hist(abs(y[(d[0]==9) | (d[0]==10) | (d[0]==11) | (d[0]==12)]),alpha = 0.3,label = \"Boundary\",weights=weights1)\n",
    "# plt.hist(abs(y[(d[0]==5) | (d[0]==6) | (d[0]==7) | (d[0]==8)]),alpha = 0.3,label = \"Droplet Phase\",weights=weights2)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "weights1 = np.ones_like(y[(d[0]==16) | (d[0]==17) | (d[0]==18)]) / (len(y[(d[0]==16) | (d[0]==17) | (d[0]==18)]))\n",
    "weights2 = np.ones_like(y[(d[0]==19) | (d[0]==20) | (d[0]==21)]) / (len(y[(d[0]==19) | (d[0]==20) | (d[0]==21)]))\n",
    "plt.hist(y[(d[0]==16) | (d[0]==17) | (d[0]==18)],alpha = 0.3,label = \"Outside Boundary\",weights=weights1)\n",
    "plt.hist(y[(d[0]==19) | (d[0]==20) | (d[0]==21)],alpha = 0.3,label = \"Non-Droplet/Boundary Phase\",weights=weights2)\n",
    "plt.xlabel(\"Directional Displacements (um)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "weights3 = np.ones_like(y[(d[0]==1)]) / (len(y[(d[0]==1)]))\n",
    "plt.hist(y[(d[0]==1)],alpha = 1,label = \"Center of Condensate\",weights=weights3)\n",
    "plt.xlabel(\"Directional Displacements (um)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n, _ = np.histogram(x,bins = 20)\n",
    "sy, _ = np.histogram(x,bins = 20,weights = y)\n",
    "sy2, _ = np.histogram(x,bins = 20,weights = y*y)\n",
    "h, x_bins, y_bins = np.histogram2d(x,y,bins = 20)\n",
    "\n",
    "mean = sy/n\n",
    "std = np.sqrt(sy2/n - mean*mean)\n",
    "plt.scatter(x,y,c = z, s = 50)\n",
    "plt.plot((_[1:] + _[:-1])/2,mean, 'r-')\n",
    "#plt.plot((_[1:] + _[:-1])/2,np.sum(h.T,axis = 1)/(np.sum(np.sum(h.T,axis = 1))))\n",
    "#plt.axvline(x=2.5*0.globals[pixel_size],linestyle = 'dashed')\n",
    "plt.errorbar((_[1:] + _[:-1])/2, mean,yerr = std/np.sqrt(len(mean)),fmt = 'r-')\n",
    "plt.xlabel(\"Distance of Localization to Boundary (um)\")\n",
    "plt.ylabel(\"Displacements (um)\")\n",
    "#plt.ylabel(\"Dapp (um^2/s)\")\n",
    "# plt.ylim((-0.2,1.25))\n",
    "# plt.xlim((-0.35,1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "n, _ = np.histogram(x,bins = 20)\n",
    "sy, _ = np.histogram(x,bins = 20,weights = y)\n",
    "sy2, _ = np.histogram(x,bins = 20,weights = y*y)\n",
    "h, x_bins, y_bins = np.histogram2d(x,y,bins = 20)\n",
    "\n",
    "mean = sy/n\n",
    "std = np.sqrt(sy2/n - mean*mean)\n",
    "plt.scatter(x,y,c = long_axis_angle, s = 50)\n",
    "plt.plot((_[1:] + _[:-1])/2,mean, 'r-')\n",
    "#plt.plot((_[1:] + _[:-1])/2,np.sum(h.T,axis = 1)/(np.sum(np.sum(h.T,axis = 1))))\n",
    "#plt.axvline(x=2.5*0.globals[pixel_size],linestyle = 'dashed')\n",
    "plt.errorbar((_[1:] + _[:-1])/2, mean,yerr = std/np.sqrt(len(mean)),fmt = 'r-')\n",
    "plt.xlabel(\"Distance of Localization to Boundary (um)\")\n",
    "plt.ylabel(\"Displacements (um)\")\n",
    "#plt.ylabel(\"Dapp (um^2/s)\")\n",
    "# plt.ylim((-0.2,1.25))\n",
    "# plt.xlim((-0.35,1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#IO_Crossing inside\n",
    "x = np.array(IO_inside_start_dist)\n",
    "y = np.array(IO_inside_start)\n",
    "xy = np.vstack([IO_inside_start_dist,IO_inside_start])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "\n",
    "n, _ = np.histogram(x,bins = 20)\n",
    "sy, _ = np.histogram(x,bins = 20,weights = y)\n",
    "sy2, _ = np.histogram(x,bins = 20,weights = y*y)\n",
    "h, x_bins, y_bins = np.histogram2d(x,y,bins = 20)\n",
    "\n",
    "mean = sy/n\n",
    "std = np.sqrt(sy2/n - mean*mean)\n",
    "plt.scatter(x,y,c = z, s = 50)\n",
    "plt.plot((_[1:] + _[:-1])/2,mean, 'r-')\n",
    "#plt.plot((_[1:] + _[:-1])/2,np.sum(h.T,axis = 1)/(np.sum(np.sum(h.T,axis = 1))))\n",
    "#plt.axvline(x=2.5*0.globals[pixel_size],linestyle = 'dashed')\n",
    "plt.errorbar((_[1:] + _[:-1])/2, mean,yerr = std/np.sqrt(len(mean)),fmt = 'r-')\n",
    "plt.xlabel(\"Distance of Localization to Boundary (um)\")\n",
    "plt.ylabel(\"Displacements (um)\")\n",
    "#plt.ylabel(\"Dapp (um^2/s)\")\n",
    "# plt.ylim((-0.2,1.25))\n",
    "# plt.xlim((-0.35,1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#IO_Crossing outside\n",
    "x = np.array(IO_outside_start_dist)\n",
    "y = np.array(IO_outside_start)\n",
    "xy = np.vstack([IO_outside_start_dist,IO_outside_start])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "\n",
    "n, _ = np.histogram(x,bins = 20)\n",
    "sy, _ = np.histogram(x,bins = 20,weights = y)\n",
    "sy2, _ = np.histogram(x,bins = 20,weights = y*y)\n",
    "h, x_bins, y_bins = np.histogram2d(x,y,bins = 20)\n",
    "\n",
    "mean = sy/n\n",
    "std = np.sqrt(sy2/n - mean*mean)\n",
    "plt.scatter(x,y,c = z, s = 50)\n",
    "plt.plot((_[1:] + _[:-1])/2,mean, 'r-')\n",
    "#plt.plot((_[1:] + _[:-1])/2,np.sum(h.T,axis = 1)/(np.sum(np.sum(h.T,axis = 1))))\n",
    "#plt.axvline(x=2.5*0.globals[pixel_size],linestyle = 'dashed')\n",
    "plt.errorbar((_[1:] + _[:-1])/2, mean,yerr = std/np.sqrt(len(mean)),fmt = 'r-')\n",
    "plt.xlabel(\"Distance of Localization to Boundary (um)\")\n",
    "plt.ylabel(\"Displacements (um)\")\n",
    "#plt.ylabel(\"Dapp (um^2/s)\")\n",
    "# plt.ylim((-0.2,1.25))\n",
    "# plt.xlim((-0.35,1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID = '0'\n",
    "cell_ID = '0'\n",
    "total_sorted_tracks = 0\n",
    "for i in range(len(rp_ez.Movie[movie_ID].Cells[cell_ID].sorted_tracks_frame[0])):\n",
    "    total_sorted_tracks += len(rp_ez.Movie[movie_ID].Cells[cell_ID].sorted_tracks_frame[0][i])\n",
    "total_sorted_tracks\n",
    "total_seg = 0\n",
    "for i,j in rp_ez.Movie[movie_ID].Cells[cell_ID].Trajectory_Collection.items():\n",
    "    total_seg += len(j.IN_Trajectory_Collection)\n",
    "    total_seg += len(j.IO_Trajectory_Collection)\n",
    "    total_seg += len(j.OUT_Trajectory_Collection)\n",
    "a = len(rp_ez.Movie[movie_ID].Cells[cell_ID].No_Drops_Trajectory_Collection)\n",
    "print(a)\n",
    "print(total_seg)\n",
    "print(total_sorted_tracks)\n",
    "print(total_seg+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cac227c059137e80483b20a8726c6d0152843f1c5edcbf7ca06b975e08a95d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
